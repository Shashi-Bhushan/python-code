{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np  \n",
    "import re  \n",
    "import nltk \n",
    "\n",
    "import time\n",
    "\n",
    "import math\n",
    " \n",
    "import pickle  \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ROOT_DIR = r'/Users/shabhushan/Desktop/python/python-code/dataset/notracking/participants'\n",
    "#ROOT_DIR = r'/home/shashi/Desktop/projects/python-code/dataset/notracking/participants'\n",
    "TRAIN_LABELS = os.path.join(ROOT_DIR, r'train', r'labels', r'labels.csv')\n",
    "TRAIN_TEXT = os.path.join(ROOT_DIR, r'train', r'extracted_data', r'extract_combined.csv')\n",
    "TEST_TEXT = os.path.join(ROOT_DIR, r'test', r'extracted_data', r'extract_combined.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# read in training and testing data\n",
    "# one dataframe for labels another for text features\n",
    "train_labels_df = pd.read_csv(TRAIN_LABELS, usecols=['document_name','is_fitara'])\n",
    "train_text_df = pd.read_csv(TRAIN_TEXT)\n",
    "test_df = pd.read_csv(TEST_TEXT)\n",
    "\n",
    "# combine labels with text features\n",
    "train_df = pd.merge(\n",
    "    train_labels_df, \n",
    "    train_text_df, \n",
    "    on='document_name', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# remove dataframes that are no longer needed from memory \n",
    "del train_labels_df\n",
    "del train_text_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_fitara'] = train_df['is_fitara'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Positive and Negative classes are size 71% and 29% respectively. Hence, no severe class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.713089\n",
       "1    0.286911\n",
       "Name: is_fitara, dtype: float64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# confirm class distribution\n",
    "# is_fitara - yes: ~29%; no: ~71%\n",
    "train_df['is_fitara'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solicitation_id                77\n",
       "contract_award_number         824\n",
       "document_name                   0\n",
       "is_fitara                       0\n",
       "contains_statement_of_work      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(TRAIN_LABELS).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_from_word_list(lst):\n",
    "    temp_set_list = [set(nltk.word_tokenize(words)) for words in lst]\n",
    "\n",
    "    return reduce(lambda x, y: {*x, *y}, temp_set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_no = get_set_from_word_list(train_df_temp)\n",
    "def get_word_frequency(df):\n",
    "    tokenized_words = [nltk.word_tokenize(words) for words in df]\n",
    "    words_list = reduce(lambda x, y: [*x, *y], tokenized_words)\n",
    "\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    vectorizer.fit_transform(words_list)\n",
    "\n",
    "    return pd.DataFrame(vectorizer.vocabulary_.items(), columns=['Text', 'Frequency']).sort_values(by='Frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(train_df, test_df):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', use_idf=True)\n",
    "    X_train = vectorizer.fit_transform(train_df)\n",
    "    \n",
    "    X_test = vectorizer.transform(test_df)\n",
    "\n",
    "    return X_train, X_test, vectorizer.get_feature_names() #pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names()), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_words = [nltk.word_tokenize(words) for words in train_df_temp]\n",
    "#words_list = reduce(lambda x, y: [*x, *y], tokenized_words)\n",
    "\n",
    "#vectorizer = CountVectorizer(stop_words='english')\n",
    "#vectorizer.fit_transform(words_list)\n",
    "\n",
    "#pd.DataFrame(vectorizer.vocabulary_.items(), columns=['Text', 'Frequency']).sort_values(by='Frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_no = train_df[train_df.is_fitara == 0]\n",
    "train_df_yes = train_df[train_df.is_fitara == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 15% of total Records for Ablation\n",
    "ablation = 0.15\n",
    "train_df_no_ablation = train_df_no.loc[0:int(len(train_df_no) * ablation)]\n",
    "train_df_yes_ablation = train_df_yes.loc[0:int(len(train_df_yes) * ablation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ablation = pd.concat([train_df_yes_ablation, train_df_no_ablation]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = train_df_ablation.drop(['is_fitara'], axis=1)\n",
    "y = train_df_ablation['is_fitara']\n",
    "\n",
    "X_train_split, X_test_split, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "#get_tf_idf(train_df_ablation['text'])\n",
    "#train_df_ablation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, feature_names = get_tf_idf(X_train_split['text'], X_test_split['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.2 ms, sys: 5.58 ms, total: 99.8 ms\n",
      "Wall time: 99.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = SVC(kernel='linear', C=100, probability=True, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      " - 1s - loss: 1.1362 - acc: 0.1667\n",
      "Epoch 2/400\n",
      " - 0s - loss: 0.9925 - acc: 0.1667\n",
      "Epoch 3/400\n",
      " - 0s - loss: 0.8584 - acc: 0.1667\n",
      "Epoch 4/400\n",
      " - 0s - loss: 0.7600 - acc: 0.2361\n",
      "Epoch 5/400\n",
      " - 0s - loss: 0.6858 - acc: 0.5972\n",
      "Epoch 6/400\n",
      " - 0s - loss: 0.6113 - acc: 0.8611\n",
      "Epoch 7/400\n",
      " - 0s - loss: 0.5652 - acc: 0.8333\n",
      "Epoch 8/400\n",
      " - 0s - loss: 0.5257 - acc: 0.8333\n",
      "Epoch 9/400\n",
      " - 0s - loss: 0.4853 - acc: 0.8333\n",
      "Epoch 10/400\n",
      " - 0s - loss: 0.4822 - acc: 0.8333\n",
      "Epoch 11/400\n",
      " - 0s - loss: 0.4597 - acc: 0.8333\n",
      "Epoch 12/400\n",
      " - 0s - loss: 0.4527 - acc: 0.8333\n",
      "Epoch 13/400\n",
      " - 0s - loss: 0.4462 - acc: 0.8333\n",
      "Epoch 14/400\n",
      " - 0s - loss: 0.4427 - acc: 0.8333\n",
      "Epoch 15/400\n",
      " - 0s - loss: 0.4436 - acc: 0.8333\n",
      "Epoch 16/400\n",
      " - 0s - loss: 0.4182 - acc: 0.8333\n",
      "Epoch 17/400\n",
      " - 0s - loss: 0.4382 - acc: 0.8333\n",
      "Epoch 18/400\n",
      " - 0s - loss: 0.4208 - acc: 0.8333\n",
      "Epoch 19/400\n",
      " - 0s - loss: 0.4198 - acc: 0.8333\n",
      "Epoch 20/400\n",
      " - 0s - loss: 0.4067 - acc: 0.8333\n",
      "Epoch 21/400\n",
      " - 0s - loss: 0.4070 - acc: 0.8333\n",
      "Epoch 22/400\n",
      " - 0s - loss: 0.4053 - acc: 0.8333\n",
      "Epoch 23/400\n",
      " - 0s - loss: 0.4042 - acc: 0.8333\n",
      "Epoch 24/400\n",
      " - 0s - loss: 0.3990 - acc: 0.8333\n",
      "Epoch 25/400\n",
      " - 0s - loss: 0.3940 - acc: 0.8333\n",
      "Epoch 26/400\n",
      " - 0s - loss: 0.3929 - acc: 0.8333\n",
      "Epoch 27/400\n",
      " - 0s - loss: 0.3992 - acc: 0.8333\n",
      "Epoch 28/400\n",
      " - 0s - loss: 0.3904 - acc: 0.8333\n",
      "Epoch 29/400\n",
      " - 0s - loss: 0.3859 - acc: 0.8333\n",
      "Epoch 30/400\n",
      " - 0s - loss: 0.3801 - acc: 0.8333\n",
      "Epoch 31/400\n",
      " - 0s - loss: 0.3662 - acc: 0.8333\n",
      "Epoch 32/400\n",
      " - 0s - loss: 0.3623 - acc: 0.8333\n",
      "Epoch 33/400\n",
      " - 0s - loss: 0.3723 - acc: 0.8333\n",
      "Epoch 34/400\n",
      " - 0s - loss: 0.3730 - acc: 0.8333\n",
      "Epoch 35/400\n",
      " - 0s - loss: 0.3484 - acc: 0.8333\n",
      "Epoch 36/400\n",
      " - 0s - loss: 0.3451 - acc: 0.8333\n",
      "Epoch 37/400\n",
      " - 0s - loss: 0.3357 - acc: 0.8333\n",
      "Epoch 38/400\n",
      " - 0s - loss: 0.3284 - acc: 0.8333\n",
      "Epoch 39/400\n",
      " - 0s - loss: 0.3230 - acc: 0.8333\n",
      "Epoch 40/400\n",
      " - 0s - loss: 0.3236 - acc: 0.8333\n",
      "Epoch 41/400\n",
      " - 0s - loss: 0.3229 - acc: 0.8333\n",
      "Epoch 42/400\n",
      " - 0s - loss: 0.3146 - acc: 0.8333\n",
      "Epoch 43/400\n",
      " - 0s - loss: 0.3046 - acc: 0.8333\n",
      "Epoch 44/400\n",
      " - 0s - loss: 0.2997 - acc: 0.8472\n",
      "Epoch 45/400\n",
      " - 0s - loss: 0.3005 - acc: 0.8333\n",
      "Epoch 46/400\n",
      " - 0s - loss: 0.2894 - acc: 0.8333\n",
      "Epoch 47/400\n",
      " - 0s - loss: 0.3003 - acc: 0.8472\n",
      "Epoch 48/400\n",
      " - 0s - loss: 0.2772 - acc: 0.8472\n",
      "Epoch 49/400\n",
      " - 0s - loss: 0.2689 - acc: 0.8472\n",
      "Epoch 50/400\n",
      " - 0s - loss: 0.2561 - acc: 0.8889\n",
      "Epoch 51/400\n",
      " - 0s - loss: 0.2575 - acc: 0.8611\n",
      "Epoch 52/400\n",
      " - 0s - loss: 0.2427 - acc: 0.8889\n",
      "Epoch 53/400\n",
      " - 0s - loss: 0.2592 - acc: 0.8611\n",
      "Epoch 54/400\n",
      " - 0s - loss: 0.2428 - acc: 0.8889\n",
      "Epoch 55/400\n",
      " - 0s - loss: 0.2236 - acc: 0.9306\n",
      "Epoch 56/400\n",
      " - 0s - loss: 0.2141 - acc: 0.9444\n",
      "Epoch 57/400\n",
      " - 0s - loss: 0.2108 - acc: 0.9306\n",
      "Epoch 58/400\n",
      " - 0s - loss: 0.2118 - acc: 0.9306\n",
      "Epoch 59/400\n",
      " - 0s - loss: 0.2111 - acc: 0.9028\n",
      "Epoch 60/400\n",
      " - 0s - loss: 0.2104 - acc: 0.9167\n",
      "Epoch 61/400\n",
      " - 0s - loss: 0.2021 - acc: 0.9306\n",
      "Epoch 62/400\n",
      " - 0s - loss: 0.1935 - acc: 0.9583\n",
      "Epoch 63/400\n",
      " - 0s - loss: 0.1786 - acc: 0.9583\n",
      "Epoch 64/400\n",
      " - 0s - loss: 0.1758 - acc: 0.9861\n",
      "Epoch 65/400\n",
      " - 0s - loss: 0.1756 - acc: 0.9583\n",
      "Epoch 66/400\n",
      " - 0s - loss: 0.1693 - acc: 0.9583\n",
      "Epoch 67/400\n",
      " - 0s - loss: 0.1556 - acc: 0.9861\n",
      "Epoch 68/400\n",
      " - 0s - loss: 0.1497 - acc: 0.9861\n",
      "Epoch 69/400\n",
      " - 0s - loss: 0.1673 - acc: 0.9583\n",
      "Epoch 70/400\n",
      " - 0s - loss: 0.1523 - acc: 0.9583\n",
      "Epoch 71/400\n",
      " - 0s - loss: 0.1466 - acc: 0.9722\n",
      "Epoch 72/400\n",
      " - 0s - loss: 0.1309 - acc: 1.0000\n",
      "Epoch 73/400\n",
      " - 0s - loss: 0.1442 - acc: 0.9722\n",
      "Epoch 74/400\n",
      " - 0s - loss: 0.1382 - acc: 0.9861\n",
      "Epoch 75/400\n",
      " - 0s - loss: 0.1357 - acc: 0.9722\n",
      "Epoch 76/400\n",
      " - 0s - loss: 0.1287 - acc: 0.9861\n",
      "Epoch 77/400\n",
      " - 0s - loss: 0.1162 - acc: 1.0000\n",
      "Epoch 78/400\n",
      " - 0s - loss: 0.1249 - acc: 1.0000\n",
      "Epoch 79/400\n",
      " - 0s - loss: 0.1137 - acc: 1.0000\n",
      "Epoch 80/400\n",
      " - 0s - loss: 0.1111 - acc: 1.0000\n",
      "Epoch 81/400\n",
      " - 0s - loss: 0.1066 - acc: 0.9861\n",
      "Epoch 82/400\n",
      " - 0s - loss: 0.1180 - acc: 0.9722\n",
      "Epoch 83/400\n",
      " - 0s - loss: 0.1079 - acc: 1.0000\n",
      "Epoch 84/400\n",
      " - 0s - loss: 0.1003 - acc: 1.0000\n",
      "Epoch 85/400\n",
      " - 0s - loss: 0.1046 - acc: 0.9861\n",
      "Epoch 86/400\n",
      " - 0s - loss: 0.0851 - acc: 1.0000\n",
      "Epoch 87/400\n",
      " - 0s - loss: 0.0918 - acc: 1.0000\n",
      "Epoch 88/400\n",
      " - 0s - loss: 0.0776 - acc: 1.0000\n",
      "Epoch 89/400\n",
      " - 0s - loss: 0.0901 - acc: 1.0000\n",
      "Epoch 90/400\n",
      " - 0s - loss: 0.0828 - acc: 1.0000\n",
      "Epoch 91/400\n",
      " - 0s - loss: 0.0789 - acc: 1.0000\n",
      "Epoch 92/400\n",
      " - 0s - loss: 0.0843 - acc: 1.0000\n",
      "Epoch 93/400\n",
      " - 0s - loss: 0.0747 - acc: 1.0000\n",
      "Epoch 94/400\n",
      " - 0s - loss: 0.0651 - acc: 1.0000\n",
      "Epoch 95/400\n",
      " - 0s - loss: 0.0713 - acc: 0.9861\n",
      "Epoch 96/400\n",
      " - 0s - loss: 0.0756 - acc: 1.0000\n",
      "Epoch 97/400\n",
      " - 0s - loss: 0.0631 - acc: 1.0000\n",
      "Epoch 98/400\n",
      " - 0s - loss: 0.0683 - acc: 1.0000\n",
      "Epoch 99/400\n",
      " - 0s - loss: 0.0686 - acc: 1.0000\n",
      "Epoch 100/400\n",
      " - 0s - loss: 0.0701 - acc: 1.0000\n",
      "Epoch 101/400\n",
      " - 0s - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 102/400\n",
      " - 0s - loss: 0.0611 - acc: 1.0000\n",
      "Epoch 103/400\n",
      " - 0s - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 104/400\n",
      " - 0s - loss: 0.0560 - acc: 1.0000\n",
      "Epoch 105/400\n",
      " - 0s - loss: 0.0604 - acc: 1.0000\n",
      "Epoch 106/400\n",
      " - 0s - loss: 0.0594 - acc: 1.0000\n",
      "Epoch 107/400\n",
      " - 0s - loss: 0.0736 - acc: 0.9861\n",
      "Epoch 108/400\n",
      " - 0s - loss: 0.0538 - acc: 1.0000\n",
      "Epoch 109/400\n",
      " - 0s - loss: 0.0605 - acc: 1.0000\n",
      "Epoch 110/400\n",
      " - 0s - loss: 0.0541 - acc: 1.0000\n",
      "Epoch 111/400\n",
      " - 0s - loss: 0.0503 - acc: 1.0000\n",
      "Epoch 112/400\n",
      " - 0s - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 113/400\n",
      " - 0s - loss: 0.0522 - acc: 0.9861\n",
      "Epoch 114/400\n",
      " - 0s - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 115/400\n",
      " - 0s - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 116/400\n",
      " - 0s - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 117/400\n",
      " - 0s - loss: 0.0473 - acc: 1.0000\n",
      "Epoch 118/400\n",
      " - 0s - loss: 0.0451 - acc: 1.0000\n",
      "Epoch 119/400\n",
      " - 0s - loss: 0.0376 - acc: 1.0000\n",
      "Epoch 120/400\n",
      " - 0s - loss: 0.0377 - acc: 1.0000\n",
      "Epoch 121/400\n",
      " - 0s - loss: 0.0469 - acc: 1.0000\n",
      "Epoch 122/400\n",
      " - 0s - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 123/400\n",
      " - 0s - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 124/400\n",
      " - 0s - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 125/400\n",
      " - 0s - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 126/400\n",
      " - 0s - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 127/400\n",
      " - 0s - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 128/400\n",
      " - 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 129/400\n",
      " - 0s - loss: 0.0469 - acc: 1.0000\n",
      "Epoch 130/400\n",
      " - 0s - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 131/400\n",
      " - 0s - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 132/400\n",
      " - 0s - loss: 0.0382 - acc: 1.0000\n",
      "Epoch 133/400\n",
      " - 0s - loss: 0.0407 - acc: 1.0000\n",
      "Epoch 134/400\n",
      " - 0s - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 135/400\n",
      " - 0s - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 136/400\n",
      " - 0s - loss: 0.0319 - acc: 1.0000\n",
      "Epoch 137/400\n",
      " - 0s - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 138/400\n",
      " - 0s - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 139/400\n",
      " - 0s - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 140/400\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 141/400\n",
      " - 0s - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 142/400\n",
      " - 0s - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 143/400\n",
      " - 0s - loss: 0.0410 - acc: 0.9861\n",
      "Epoch 144/400\n",
      " - 0s - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 145/400\n",
      " - 0s - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 146/400\n",
      " - 0s - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 147/400\n",
      " - 0s - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 148/400\n",
      " - 0s - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 149/400\n",
      " - 0s - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 150/400\n",
      " - 0s - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 151/400\n",
      " - 0s - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 152/400\n",
      " - 0s - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 153/400\n",
      " - 0s - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 154/400\n",
      " - 0s - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 155/400\n",
      " - 0s - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 156/400\n",
      " - 0s - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 157/400\n",
      " - 0s - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 158/400\n",
      " - 0s - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 159/400\n",
      " - 0s - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 160/400\n",
      " - 0s - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 161/400\n",
      " - 0s - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 162/400\n",
      " - 0s - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 163/400\n",
      " - 0s - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 164/400\n",
      " - 0s - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 165/400\n",
      " - 0s - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 166/400\n",
      " - 0s - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 167/400\n",
      " - 0s - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 168/400\n",
      " - 0s - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 169/400\n",
      " - 0s - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 170/400\n",
      " - 0s - loss: 0.0174 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/400\n",
      " - 0s - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 172/400\n",
      " - 0s - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 173/400\n",
      " - 0s - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 174/400\n",
      " - 0s - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 175/400\n",
      " - 0s - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 176/400\n",
      " - 0s - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 177/400\n",
      " - 0s - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 178/400\n",
      " - 0s - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 179/400\n",
      " - 0s - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 180/400\n",
      " - 0s - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 181/400\n",
      " - 0s - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 182/400\n",
      " - 0s - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 183/400\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 184/400\n",
      " - 0s - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 185/400\n",
      " - 0s - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 186/400\n",
      " - 0s - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 187/400\n",
      " - 0s - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 188/400\n",
      " - 0s - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 189/400\n",
      " - 0s - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 190/400\n",
      " - 0s - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 191/400\n",
      " - 0s - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 192/400\n",
      " - 0s - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 193/400\n",
      " - 0s - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 194/400\n",
      " - 0s - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 195/400\n",
      " - 0s - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 196/400\n",
      " - 0s - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 197/400\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 198/400\n",
      " - 0s - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 199/400\n",
      " - 0s - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 200/400\n",
      " - 0s - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 201/400\n",
      " - 0s - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 202/400\n",
      " - 0s - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 203/400\n",
      " - 0s - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 204/400\n",
      " - 0s - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 205/400\n",
      " - 0s - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 206/400\n",
      " - 0s - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 207/400\n",
      " - 0s - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 208/400\n",
      " - 0s - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 209/400\n",
      " - 0s - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 210/400\n",
      " - 0s - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 211/400\n",
      " - 0s - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 212/400\n",
      " - 0s - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 213/400\n",
      " - 0s - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 214/400\n",
      " - 0s - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 215/400\n",
      " - 0s - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 216/400\n",
      " - 0s - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 217/400\n",
      " - 0s - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 218/400\n",
      " - 0s - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 219/400\n",
      " - 0s - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 220/400\n",
      " - 0s - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 221/400\n",
      " - 0s - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 222/400\n",
      " - 0s - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 223/400\n",
      " - 0s - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 224/400\n",
      " - 0s - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 225/400\n",
      " - 0s - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 226/400\n",
      " - 0s - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 227/400\n",
      " - 0s - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 228/400\n",
      " - 0s - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 229/400\n",
      " - 0s - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 230/400\n",
      " - 0s - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 231/400\n",
      " - 0s - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 232/400\n",
      " - 0s - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 233/400\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 234/400\n",
      " - 0s - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 235/400\n",
      " - 0s - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 236/400\n",
      " - 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 237/400\n",
      " - 0s - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 238/400\n",
      " - 0s - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 239/400\n",
      " - 0s - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 240/400\n",
      " - 0s - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 241/400\n",
      " - 0s - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 242/400\n",
      " - 0s - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 243/400\n",
      " - 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 244/400\n",
      " - 0s - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 245/400\n",
      " - 0s - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 246/400\n",
      " - 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 247/400\n",
      " - 0s - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 248/400\n",
      " - 0s - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 249/400\n",
      " - 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 250/400\n",
      " - 0s - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 251/400\n",
      " - 0s - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 252/400\n",
      " - 0s - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 253/400\n",
      " - 0s - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 254/400\n",
      " - 0s - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 255/400\n",
      " - 0s - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 256/400\n",
      " - 0s - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 257/400\n",
      " - 0s - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 258/400\n",
      " - 0s - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 259/400\n",
      " - 0s - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 260/400\n",
      " - 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 261/400\n",
      " - 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 262/400\n",
      " - 0s - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 263/400\n",
      " - 0s - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 264/400\n",
      " - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 265/400\n",
      " - 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 266/400\n",
      " - 0s - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 267/400\n",
      " - 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 268/400\n",
      " - 0s - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 269/400\n",
      " - 0s - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 270/400\n",
      " - 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 271/400\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 272/400\n",
      " - 0s - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 273/400\n",
      " - 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 274/400\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 275/400\n",
      " - 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 276/400\n",
      " - 0s - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 277/400\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 278/400\n",
      " - 0s - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 279/400\n",
      " - 0s - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 280/400\n",
      " - 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 281/400\n",
      " - 0s - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 282/400\n",
      " - 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 283/400\n",
      " - 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 284/400\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 285/400\n",
      " - 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 286/400\n",
      " - 0s - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 287/400\n",
      " - 0s - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 288/400\n",
      " - 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 289/400\n",
      " - 0s - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 290/400\n",
      " - 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 291/400\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 292/400\n",
      " - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 293/400\n",
      " - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 294/400\n",
      " - 0s - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 295/400\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 296/400\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 297/400\n",
      " - 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 298/400\n",
      " - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 299/400\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 300/400\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 301/400\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 302/400\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 303/400\n",
      " - 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 304/400\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 305/400\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 306/400\n",
      " - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 307/400\n",
      " - 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 308/400\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 309/400\n",
      " - 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 310/400\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 311/400\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 312/400\n",
      " - 0s - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 313/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 314/400\n",
      " - 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 315/400\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 316/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 317/400\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 318/400\n",
      " - 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 319/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 320/400\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 321/400\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 322/400\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 323/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 324/400\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 325/400\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 326/400\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 327/400\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 328/400\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 329/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 330/400\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 331/400\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 332/400\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 333/400\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 334/400\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 335/400\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 336/400\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 337/400\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 338/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 339/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 340/400\n",
      " - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 341/400\n",
      " - 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 342/400\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 343/400\n",
      " - 0s - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 344/400\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 345/400\n",
      " - 0s - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 346/400\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 347/400\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 348/400\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 349/400\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 350/400\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 351/400\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 352/400\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 353/400\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 354/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 355/400\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 356/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 357/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 358/400\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 359/400\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 360/400\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 361/400\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 362/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 363/400\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 364/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 365/400\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 366/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 367/400\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 368/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 369/400\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 370/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 371/400\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 372/400\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 373/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 374/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 375/400\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 376/400\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 377/400\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 378/400\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 379/400\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 380/400\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 381/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 382/400\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 383/400\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 384/400\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 385/400\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 386/400\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 387/400\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 388/400\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 389/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 390/400\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 391/400\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 392/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 393/400\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 394/400\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 395/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 396/400\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 397/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 398/400\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 399/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 400/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(35, input_dim=X_train.toarray().shape[1], activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train.toarray(), to_categorical(y_train, 2), epochs=400, batch_size=10, verbose=2)#, class_weight={1:0.96, 0:0.04})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot metrics\n",
    "plt.plot(history.history['acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5901795320338957\n",
      "0.5542277741625697\n",
      "[0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#print(y_test.values)\n",
    "#print(pred)\n",
    "#print(pred_proba)\n",
    "\n",
    "num = metrics.log_loss(y_test.values, model.predict(X_test))\n",
    "\n",
    "\n",
    "#math.exp(-num)\n",
    "print(num)\n",
    "print(math.exp(-num))\n",
    "print(y_test.values)\n",
    "print(np.round(model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time.time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.log_loss(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \"\"\"\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        #if opts.print_top10 and feature_names is not None:\n",
    "        print(\"top 10 keywords per class:\")\n",
    "        for i, label in enumerate(target_names):\n",
    "            top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "            print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "    \"\"\"\n",
    "    #if opts.print_report:\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred))\n",
    "\n",
    "    #if opts.print_cm:\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None, solver='sag',\n",
      "                tol=0.01)\n",
      "train time: 0.009s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=50, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.006s\n",
      "test time:  0.001s\n",
      "accuracy:   10.074\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.71        24\n",
      "   macro avg       0.42      0.40      0.41        24\n",
      "weighted avg       0.74      0.71      0.73        24\n",
      "\n",
      "confusion matrix:\n",
      "[[17  4]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
      "                            n_jobs=None, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False)\n",
      "train time: 0.004s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "                     weights='uniform')\n",
      "train time: 0.001s\n",
      "test time:  0.004s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "train time: 0.107s\n",
      "test time:  0.008s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50, tol=1e-3), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50, tol=1e-3),\n",
    "         \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 0.014s\n",
      "test time:  0.000s\n",
      "accuracy:   5.756\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.43      0.48      0.45        24\n",
      "weighted avg       0.76      0.83      0.80        24\n",
      "\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.002s\n",
      "test time:  0.000s\n",
      "accuracy:   5.756\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.43      0.48      0.45        24\n",
      "weighted avg       0.76      0.83      0.80        24\n",
      "\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 0.005s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.005s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.006s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.002s\n",
      "test time:  0.001s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.002s\n",
      "accuracy:   5.756\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.43      0.48      0.45        24\n",
      "weighted avg       0.76      0.83      0.80        24\n",
      "\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1, class_prior=None, fit_prior=True, norm=False)\n",
      "train time: 0.002s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "         steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None,\n",
      "                                                     dual=False,\n",
      "                                                     fit_intercept=True,\n",
      "                                                     intercept_scaling=1,\n",
      "                                                     loss='squared_hinge',\n",
      "                                                     max_iter=1000,\n",
      "                                                     multi_class='ovr',\n",
      "                                                     penalty='l1',\n",
      "                                                     random_state=None,\n",
      "                                                     tol=0.001, verbose=0),\n",
      "                                 max_features=None, norm_order=1, prefit=False,\n",
      "                                 threshold=None)),\n",
      "                ('classification',\n",
      "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                           fit_intercept=True, intercept_scaling=1,\n",
      "                           loss='squared_hinge', max_iter=1000,\n",
      "                           multi_class='ovr', penalty='l2', random_state=None,\n",
      "                           tol=0.0001, verbose=0))],\n",
      "         verbose=False)\n",
      "train time: 0.006s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=.1)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
