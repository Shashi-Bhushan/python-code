{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import all the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np  \n",
    "import re  \n",
    "import nltk \n",
    "\n",
    "import time\n",
    "\n",
    "import math\n",
    " \n",
    "import pickle  \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test DF\n",
    "\n",
    "Create Training and Testing Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ROOT_DIR = r'/Users/shabhushan/Desktop/python/python-code/dataset/notracking/participants'\n",
    "#ROOT_DIR = r'/home/shashi/Desktop/projects/python-code/dataset/notracking/participants'\n",
    "TRAIN_LABELS = os.path.join(ROOT_DIR, r'train', r'labels', r'labels.csv')\n",
    "TRAIN_TEXT = os.path.join(ROOT_DIR, r'train', r'extracted_data', r'extract_combined.csv')\n",
    "TEST_TEXT = os.path.join(ROOT_DIR, r'test', r'extracted_data', r'extract_combined.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# read in training and testing data\n",
    "# one dataframe for labels another for text features\n",
    "train_labels_df = pd.read_csv(TRAIN_LABELS, usecols=['document_name','is_fitara'])\n",
    "train_text_df = pd.read_csv(TRAIN_TEXT)\n",
    "test_df = pd.read_csv(TEST_TEXT)\n",
    "\n",
    "# combine labels with text features\n",
    "train_df = pd.merge(\n",
    "    train_labels_df, \n",
    "    train_text_df, \n",
    "    on='document_name', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# remove dataframes that are no longer needed from memory \n",
    "del train_labels_df\n",
    "del train_text_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_fitara'] = train_df['is_fitara'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "Primilinary Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Positive and Negative classes are size 71% and 29% respectively. Hence, no severe class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.713089\n",
       "1    0.286911\n",
       "Name: is_fitara, dtype: float64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# confirm class distribution\n",
    "# is_fitara - yes: ~29%; no: ~71%\n",
    "train_df['is_fitara'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solicitation_id                77\n",
       "contract_award_number         824\n",
       "document_name                   0\n",
       "is_fitara                       0\n",
       "contains_statement_of_work      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(TRAIN_LABELS).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Tokenization and Lemmatization\n",
    "\n",
    "First, we need to remove the stop words, punctuation characters and all other special characters from the text.\n",
    "Then, we need to lemmatize the word to it's root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# default tag is Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "words = train_df.loc[0, 'text']\n",
    "\n",
    "def lemmatize(words):\n",
    "    # Remove Stop words and keep only Alpha Numeric words\n",
    "    words = [word.lower() for word in nltk.word_tokenize(words) if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "    return ' '.join([lemma.lemmatize(token, tag_map[tag[0]]) for token, tag in nltk.pos_tag(words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 344 ms, total: 2min 36s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df['text'] = train_df.loc[:, 'text'].apply(lemmatize)\n",
    "test_df['text'] = test_df.loc[:, 'text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions\n",
    "\n",
    "Some Utility Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_from_word_list(lst):\n",
    "    temp_set_list = [set(nltk.word_tokenize(words)) for words in lst]\n",
    "\n",
    "    return reduce(lambda x, y: {*x, *y}, temp_set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_no = get_set_from_word_list(train_df_temp)\n",
    "def get_word_frequency(df):\n",
    "    tokenized_words = [nltk.word_tokenize(words) for words in df]\n",
    "    words_list = reduce(lambda x, y: [*x, *y], tokenized_words)\n",
    "\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    vectorizer.fit_transform(words_list)\n",
    "\n",
    "    return pd.DataFrame(vectorizer.vocabulary_.items(), columns=['Text', 'Frequency']).sort_values(by='Frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(train_df, test_df):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', use_idf=True)\n",
    "    X_train = vectorizer.fit_transform(train_df)\n",
    "    \n",
    "    X_test = vectorizer.transform(test_df)\n",
    "\n",
    "    return X_train, X_test, vectorizer.get_feature_names() #pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names()), X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Experiment\n",
    "\n",
    "Experimentation on a Smaller Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_no = train_df[train_df.is_fitara == 0]\n",
    "train_df_yes = train_df[train_df.is_fitara == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 15% of total Records for Ablation\n",
    "ablation = 0.15\n",
    "train_df_no_ablation = train_df_no.loc[0:int(len(train_df_no) * ablation)]\n",
    "train_df_yes_ablation = train_df_yes.loc[0:int(len(train_df_yes) * ablation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ablation = pd.concat([train_df_yes_ablation, train_df_no_ablation]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = train_df_ablation.drop(['is_fitara'], axis=1)\n",
    "y = train_df_ablation['is_fitara']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.073909731527722\n",
      "[1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "CPU times: user 63.9 ms, sys: 2.06 ms, total: 65.9 ms\n",
      "Wall time: 64.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# X_train, X_test, feature_names = get_tf_idf(X_train_split['text'], X_test_split['text'])\n",
    "\n",
    "# build pipeline\n",
    "vectorizer = TfidfVectorizer()\n",
    "regressor = SVC()\n",
    "\n",
    "pipeline = Pipeline([('vectorizer', vectorizer), ('Logistic Regression', MultinomialNB(alpha=.01))])\n",
    "\n",
    "# fit pipeline\n",
    "pipeline.fit(X_train['text'], y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = pipeline.predict(X_test['text'])\n",
    "\n",
    "print(metrics.log_loss(y_test.values, y_pred))\n",
    "print(y_pred)\n",
    "print(y_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "CPU times: user 69.9 ms, sys: 2.25 ms, total: 72.1 ms\n",
      "Wall time: 70.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shabhushan/.local/share/virtualenvs/python-code-Ervzvb6E/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_lr, X_test_lr, _ = get_tf_idf(X_train['text'], X_test['text'])\n",
    "#model = SVC(kernel='linear', C=100, probability=True, random_state=32)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_lr, y_train)\n",
    "\n",
    "pred = model.predict(X_test_lr)\n",
    "pred_proba = model.predict_proba(X_test_lr)\n",
    "\n",
    "print(y_test.values)\n",
    "print(pred)\n",
    "print(np.round(pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      " - 2s - loss: 0.4845 - acc: 0.8194\n",
      "Epoch 2/400\n",
      " - 0s - loss: 0.4710 - acc: 0.8194\n",
      "Epoch 3/400\n",
      " - 0s - loss: 0.4598 - acc: 0.8194\n",
      "Epoch 4/400\n",
      " - 0s - loss: 0.4694 - acc: 0.8194\n",
      "Epoch 5/400\n",
      " - 0s - loss: 0.4584 - acc: 0.8194\n",
      "Epoch 6/400\n",
      " - 0s - loss: 0.4575 - acc: 0.8194\n",
      "Epoch 7/400\n",
      " - 0s - loss: 0.4531 - acc: 0.8194\n",
      "Epoch 8/400\n",
      " - 0s - loss: 0.4481 - acc: 0.8194\n",
      "Epoch 9/400\n",
      " - 0s - loss: 0.4258 - acc: 0.8194\n",
      "Epoch 10/400\n",
      " - 0s - loss: 0.4403 - acc: 0.8194\n",
      "Epoch 11/400\n",
      " - 0s - loss: 0.4307 - acc: 0.8194\n",
      "Epoch 12/400\n",
      " - 0s - loss: 0.4228 - acc: 0.8194\n",
      "Epoch 13/400\n",
      " - 0s - loss: 0.4268 - acc: 0.8194\n",
      "Epoch 14/400\n",
      " - 0s - loss: 0.4277 - acc: 0.8194\n",
      "Epoch 15/400\n",
      " - 0s - loss: 0.4141 - acc: 0.8194\n",
      "Epoch 16/400\n",
      " - 0s - loss: 0.4016 - acc: 0.8194\n",
      "Epoch 17/400\n",
      " - 0s - loss: 0.4073 - acc: 0.8194\n",
      "Epoch 18/400\n",
      " - 0s - loss: 0.3831 - acc: 0.8194\n",
      "Epoch 19/400\n",
      " - 0s - loss: 0.3867 - acc: 0.8194\n",
      "Epoch 20/400\n",
      " - 0s - loss: 0.3681 - acc: 0.8194\n",
      "Epoch 21/400\n",
      " - 0s - loss: 0.3662 - acc: 0.8194\n",
      "Epoch 22/400\n",
      " - 0s - loss: 0.3401 - acc: 0.8194\n",
      "Epoch 23/400\n",
      " - 0s - loss: 0.3408 - acc: 0.8194\n",
      "Epoch 24/400\n",
      " - 0s - loss: 0.3512 - acc: 0.8194\n",
      "Epoch 25/400\n",
      " - 0s - loss: 0.3350 - acc: 0.8194\n",
      "Epoch 26/400\n",
      " - 0s - loss: 0.3214 - acc: 0.8194\n",
      "Epoch 27/400\n",
      " - 0s - loss: 0.3166 - acc: 0.8194\n",
      "Epoch 28/400\n",
      " - 0s - loss: 0.3031 - acc: 0.8333\n",
      "Epoch 29/400\n",
      " - 0s - loss: 0.2876 - acc: 0.8194\n",
      "Epoch 30/400\n",
      " - 0s - loss: 0.2894 - acc: 0.8611\n",
      "Epoch 31/400\n",
      " - 0s - loss: 0.2652 - acc: 0.8611\n",
      "Epoch 32/400\n",
      " - 0s - loss: 0.2549 - acc: 0.8472\n",
      "Epoch 33/400\n",
      " - 0s - loss: 0.2594 - acc: 0.8611\n",
      "Epoch 34/400\n",
      " - 0s - loss: 0.2479 - acc: 0.8611\n",
      "Epoch 35/400\n",
      " - 0s - loss: 0.2248 - acc: 0.8889\n",
      "Epoch 36/400\n",
      " - 0s - loss: 0.2197 - acc: 0.9306\n",
      "Epoch 37/400\n",
      " - 0s - loss: 0.2027 - acc: 0.9306\n",
      "Epoch 38/400\n",
      " - 0s - loss: 0.2022 - acc: 0.9028\n",
      "Epoch 39/400\n",
      " - 0s - loss: 0.2015 - acc: 0.9028\n",
      "Epoch 40/400\n",
      " - 0s - loss: 0.1744 - acc: 0.9444\n",
      "Epoch 41/400\n",
      " - 0s - loss: 0.1780 - acc: 0.9306\n",
      "Epoch 42/400\n",
      " - 0s - loss: 0.1597 - acc: 0.9444\n",
      "Epoch 43/400\n",
      " - 0s - loss: 0.1597 - acc: 0.9583\n",
      "Epoch 44/400\n",
      " - 0s - loss: 0.1534 - acc: 0.9722\n",
      "Epoch 45/400\n",
      " - 0s - loss: 0.1440 - acc: 1.0000\n",
      "Epoch 46/400\n",
      " - 0s - loss: 0.1376 - acc: 1.0000\n",
      "Epoch 47/400\n",
      " - 0s - loss: 0.1351 - acc: 0.9861\n",
      "Epoch 48/400\n",
      " - 0s - loss: 0.1246 - acc: 1.0000\n",
      "Epoch 49/400\n",
      " - 0s - loss: 0.1212 - acc: 0.9861\n",
      "Epoch 50/400\n",
      " - 0s - loss: 0.1256 - acc: 0.9722\n",
      "Epoch 51/400\n",
      " - 0s - loss: 0.1152 - acc: 1.0000\n",
      "Epoch 52/400\n",
      " - 0s - loss: 0.1240 - acc: 0.9583\n",
      "Epoch 53/400\n",
      " - 0s - loss: 0.1201 - acc: 0.9861\n",
      "Epoch 54/400\n",
      " - 0s - loss: 0.1022 - acc: 0.9861\n",
      "Epoch 55/400\n",
      " - 0s - loss: 0.0960 - acc: 1.0000\n",
      "Epoch 56/400\n",
      " - 0s - loss: 0.1008 - acc: 0.9861\n",
      "Epoch 57/400\n",
      " - 0s - loss: 0.0938 - acc: 0.9861\n",
      "Epoch 58/400\n",
      " - 0s - loss: 0.0863 - acc: 1.0000\n",
      "Epoch 59/400\n",
      " - 0s - loss: 0.0765 - acc: 1.0000\n",
      "Epoch 60/400\n",
      " - 0s - loss: 0.0788 - acc: 1.0000\n",
      "Epoch 61/400\n",
      " - 0s - loss: 0.0805 - acc: 1.0000\n",
      "Epoch 62/400\n",
      " - 0s - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 63/400\n",
      " - 0s - loss: 0.0648 - acc: 1.0000\n",
      "Epoch 64/400\n",
      " - 0s - loss: 0.0734 - acc: 0.9861\n",
      "Epoch 65/400\n",
      " - 0s - loss: 0.0616 - acc: 1.0000\n",
      "Epoch 66/400\n",
      " - 0s - loss: 0.0594 - acc: 1.0000\n",
      "Epoch 67/400\n",
      " - 0s - loss: 0.0556 - acc: 1.0000\n",
      "Epoch 68/400\n",
      " - 0s - loss: 0.0532 - acc: 1.0000\n",
      "Epoch 69/400\n",
      " - 0s - loss: 0.0574 - acc: 1.0000\n",
      "Epoch 70/400\n",
      " - 0s - loss: 0.0623 - acc: 1.0000\n",
      "Epoch 71/400\n",
      " - 0s - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 72/400\n",
      " - 0s - loss: 0.0463 - acc: 1.0000\n",
      "Epoch 73/400\n",
      " - 0s - loss: 0.0559 - acc: 1.0000\n",
      "Epoch 74/400\n",
      " - 0s - loss: 0.0531 - acc: 1.0000\n",
      "Epoch 75/400\n",
      " - 0s - loss: 0.0491 - acc: 1.0000\n",
      "Epoch 76/400\n",
      " - 0s - loss: 0.0434 - acc: 1.0000\n",
      "Epoch 77/400\n",
      " - 0s - loss: 0.0478 - acc: 1.0000\n",
      "Epoch 78/400\n",
      " - 0s - loss: 0.0453 - acc: 1.0000\n",
      "Epoch 79/400\n",
      " - 0s - loss: 0.0423 - acc: 1.0000\n",
      "Epoch 80/400\n",
      " - 0s - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 81/400\n",
      " - 0s - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 82/400\n",
      " - 0s - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 83/400\n",
      " - 0s - loss: 0.0386 - acc: 1.0000\n",
      "Epoch 84/400\n",
      " - 0s - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 85/400\n",
      " - 0s - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 86/400\n",
      " - 0s - loss: 0.0363 - acc: 1.0000\n",
      "Epoch 87/400\n",
      " - 0s - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 88/400\n",
      " - 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 89/400\n",
      " - 0s - loss: 0.0306 - acc: 1.0000\n",
      "Epoch 90/400\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 91/400\n",
      " - 0s - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 92/400\n",
      " - 0s - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 93/400\n",
      " - 0s - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 94/400\n",
      " - 0s - loss: 0.0295 - acc: 1.0000\n",
      "Epoch 95/400\n",
      " - 0s - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 96/400\n",
      " - 0s - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 97/400\n",
      " - 0s - loss: 0.0288 - acc: 1.0000\n",
      "Epoch 98/400\n",
      " - 0s - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 99/400\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 100/400\n",
      " - 0s - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 101/400\n",
      " - 0s - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 102/400\n",
      " - 0s - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 103/400\n",
      " - 0s - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 104/400\n",
      " - 0s - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 105/400\n",
      " - 0s - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 106/400\n",
      " - 0s - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 107/400\n",
      " - 0s - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 108/400\n",
      " - 0s - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 109/400\n",
      " - 0s - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 110/400\n",
      " - 0s - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 111/400\n",
      " - 0s - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 112/400\n",
      " - 0s - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 113/400\n",
      " - 0s - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 114/400\n",
      " - 0s - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 115/400\n",
      " - 0s - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 116/400\n",
      " - 0s - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 117/400\n",
      " - 0s - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 118/400\n",
      " - 0s - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 119/400\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 120/400\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 121/400\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 122/400\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 123/400\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 124/400\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 125/400\n",
      " - 0s - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 126/400\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 127/400\n",
      " - 0s - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 128/400\n",
      " - 0s - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 129/400\n",
      " - 0s - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 130/400\n",
      " - 0s - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 131/400\n",
      " - 0s - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 132/400\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 133/400\n",
      " - 0s - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 134/400\n",
      " - 0s - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 135/400\n",
      " - 0s - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 136/400\n",
      " - 0s - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 137/400\n",
      " - 0s - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 138/400\n",
      " - 0s - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 139/400\n",
      " - 0s - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 140/400\n",
      " - 0s - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 141/400\n",
      " - 0s - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 142/400\n",
      " - 0s - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 143/400\n",
      " - 0s - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 144/400\n",
      " - 0s - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 145/400\n",
      " - 0s - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 146/400\n",
      " - 0s - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 147/400\n",
      " - 0s - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 148/400\n",
      " - 0s - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 149/400\n",
      " - 0s - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 150/400\n",
      " - 0s - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 151/400\n",
      " - 0s - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 152/400\n",
      " - 0s - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 153/400\n",
      " - 0s - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 154/400\n",
      " - 0s - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 155/400\n",
      " - 0s - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 156/400\n",
      " - 0s - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 157/400\n",
      " - 0s - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 158/400\n",
      " - 0s - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 159/400\n",
      " - 0s - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 160/400\n",
      " - 0s - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 161/400\n",
      " - 0s - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 162/400\n",
      " - 0s - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 163/400\n",
      " - 0s - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 164/400\n",
      " - 0s - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 165/400\n",
      " - 0s - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 166/400\n",
      " - 0s - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 167/400\n",
      " - 0s - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 168/400\n",
      " - 0s - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 169/400\n",
      " - 0s - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 170/400\n",
      " - 0s - loss: 0.0079 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/400\n",
      " - 0s - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 172/400\n",
      " - 0s - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 173/400\n",
      " - 0s - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 174/400\n",
      " - 0s - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 175/400\n",
      " - 0s - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 176/400\n",
      " - 0s - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 177/400\n",
      " - 0s - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 178/400\n",
      " - 0s - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 179/400\n",
      " - 0s - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 180/400\n",
      " - 0s - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 181/400\n",
      " - 0s - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 182/400\n",
      " - 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 183/400\n",
      " - 0s - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 184/400\n",
      " - 0s - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 185/400\n",
      " - 0s - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 186/400\n",
      " - 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 187/400\n",
      " - 0s - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 188/400\n",
      " - 0s - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 189/400\n",
      " - 0s - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 190/400\n",
      " - 0s - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 191/400\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 192/400\n",
      " - 0s - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 193/400\n",
      " - 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 194/400\n",
      " - 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 195/400\n",
      " - 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 196/400\n",
      " - 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 197/400\n",
      " - 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 198/400\n",
      " - 0s - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 199/400\n",
      " - 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 200/400\n",
      " - 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 201/400\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 202/400\n",
      " - 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 203/400\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 204/400\n",
      " - 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 205/400\n",
      " - 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 206/400\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 207/400\n",
      " - 0s - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 208/400\n",
      " - 0s - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 209/400\n",
      " - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 210/400\n",
      " - 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 211/400\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 212/400\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 213/400\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 214/400\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 215/400\n",
      " - 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 216/400\n",
      " - 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 217/400\n",
      " - 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 218/400\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 219/400\n",
      " - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 220/400\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 221/400\n",
      " - 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 222/400\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 223/400\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 224/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 225/400\n",
      " - 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 226/400\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 227/400\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 228/400\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 229/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 230/400\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 231/400\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 232/400\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 233/400\n",
      " - 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 234/400\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 235/400\n",
      " - 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 236/400\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 237/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 238/400\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 239/400\n",
      " - 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 240/400\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 241/400\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 242/400\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 243/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 244/400\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 245/400\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 246/400\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 247/400\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 248/400\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 249/400\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 250/400\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 251/400\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 252/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 253/400\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 254/400\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 255/400\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 256/400\n",
      " - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 257/400\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 258/400\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 259/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 260/400\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 261/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 262/400\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 263/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 264/400\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 265/400\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 266/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 267/400\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 268/400\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 269/400\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 270/400\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 271/400\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 272/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 273/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 274/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 275/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 276/400\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 277/400\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 278/400\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 279/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 280/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 281/400\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 282/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 283/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 284/400\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 285/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 286/400\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 287/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 288/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 289/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 290/400\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 291/400\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 292/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 293/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 294/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 295/400\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 296/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 297/400\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 298/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 299/400\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 300/400\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 301/400\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 302/400\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 303/400\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 304/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 305/400\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 306/400\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 307/400\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 308/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 309/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 310/400\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 311/400\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 312/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 313/400\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 314/400\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 315/400\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 316/400\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 317/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 318/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 319/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 320/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 321/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 322/400\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 323/400\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 324/400\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 325/400\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 326/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 327/400\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 328/400\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 329/400\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 330/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 331/400\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 332/400\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 333/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 334/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 335/400\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 336/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 337/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 338/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 339/400\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 340/400\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 341/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 342/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 343/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 344/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 345/400\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 346/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 347/400\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 348/400\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 349/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 350/400\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 351/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 352/400\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 353/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 354/400\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 355/400\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 356/400\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 357/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 358/400\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 359/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 360/400\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 361/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 362/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 363/400\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 364/400\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 365/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 366/400\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 367/400\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 368/400\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 369/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 370/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 371/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 372/400\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 373/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 374/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 375/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 376/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 377/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 378/400\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 379/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 380/400\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 381/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 382/400\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 383/400\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 384/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 385/400\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 386/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 387/400\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 388/400\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 389/400\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 390/400\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 391/400\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 392/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 393/400\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 394/400\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 395/400\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 396/400\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 397/400\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 398/400\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 399/400\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 400/400\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=X_train.toarray().shape[1], activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train.toarray(), to_categorical(y_train, 2), epochs=400, batch_size=10, verbose=2)#, class_weight={1:0.96, 0:0.04})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot metrics\n",
    "plt.plot(history.history['acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867862403792969\n",
      "0.556111625063531\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#print(y_test.values)\n",
    "#print(pred)\n",
    "#print(pred_proba)\n",
    "\n",
    "num = metrics.log_loss(y_test.values, model.predict(X_test))\n",
    "\n",
    "\n",
    "#math.exp(-num)\n",
    "print(num)\n",
    "print(math.exp(-num))\n",
    "print(y_test.values)\n",
    "print(np.round(model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% Accuracy on Abration Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the model on Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['is_fitara'], axis=1)\n",
    "y = train_df['is_fitara']\n",
    "\n",
    "X_train_split, X_test_split, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "X_train, X_test, feature_names = get_tf_idf(X_train_split['text'], X_test_split['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 3s - loss: 0.6077 - acc: 0.7053\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.5733 - acc: 0.7053\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5444 - acc: 0.7081\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5127 - acc: 0.7207\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4614 - acc: 0.7542\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.4174 - acc: 0.8045\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3594 - acc: 0.8757\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3286 - acc: 0.8729\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2717 - acc: 0.9190\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2474 - acc: 0.9148\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2330 - acc: 0.9232\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.2025 - acc: 0.9372\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1844 - acc: 0.9413\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1616 - acc: 0.9469\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1451 - acc: 0.9553\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1256 - acc: 0.9581\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1109 - acc: 0.9679\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.1094 - acc: 0.9623\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0975 - acc: 0.9721\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0843 - acc: 0.9777\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0832 - acc: 0.9749\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0738 - acc: 0.9791\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0725 - acc: 0.9804\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0634 - acc: 0.9846\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0631 - acc: 0.9846\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0518 - acc: 0.9832\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0443 - acc: 0.9902\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0495 - acc: 0.9846\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0409 - acc: 0.9902\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0393 - acc: 0.9888\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0482 - acc: 0.9832\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0418 - acc: 0.9916\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0450 - acc: 0.9818\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0321 - acc: 0.9944\n",
      "Epoch 35/100\n",
      " - 2s - loss: 0.0388 - acc: 0.9874\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0323 - acc: 0.9902\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.0429 - acc: 0.9888\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0278 - acc: 0.9888\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0323 - acc: 0.9916\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.0316 - acc: 0.9902\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.0298 - acc: 0.9888\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0313 - acc: 0.9902\n",
      "Epoch 43/100\n",
      " - 2s - loss: 0.0292 - acc: 0.9902\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0274 - acc: 0.9874\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0273 - acc: 0.9888\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0291 - acc: 0.9902\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0213 - acc: 0.9930\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.0272 - acc: 0.9930\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.0263 - acc: 0.9916\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.0124 - acc: 0.9986\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.0186 - acc: 0.9958\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.0159 - acc: 0.9958\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.0145 - acc: 0.9986\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0277 - acc: 0.9916\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0196 - acc: 0.9930\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.0149 - acc: 0.9930\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0090 - acc: 0.9986\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0160 - acc: 0.9944\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.0157 - acc: 0.9944\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.0136 - acc: 0.9958\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.0195 - acc: 0.9958\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.0138 - acc: 0.9930\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.0249 - acc: 0.9902\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.0140 - acc: 0.9972\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.0166 - acc: 0.9958\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.0149 - acc: 0.9944\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.0154 - acc: 0.9958\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.0230 - acc: 0.9944\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.0140 - acc: 0.9958\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.0137 - acc: 0.9972\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.0170 - acc: 0.9944\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.0100 - acc: 0.9944\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.0181 - acc: 0.9958\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.0109 - acc: 0.9944\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.0162 - acc: 0.9958\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.0151 - acc: 0.9930\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.0131 - acc: 0.9944\n",
      "Epoch 79/100\n",
      " - 2s - loss: 0.0116 - acc: 0.9958\n",
      "Epoch 80/100\n",
      " - 2s - loss: 0.0140 - acc: 0.9958\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.0109 - acc: 0.9972\n",
      "Epoch 82/100\n",
      " - 2s - loss: 0.0089 - acc: 0.9986\n",
      "Epoch 83/100\n",
      " - 2s - loss: 0.0145 - acc: 0.9944\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.0123 - acc: 0.9944\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.0187 - acc: 0.9944\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.0136 - acc: 0.9958\n",
      "Epoch 87/100\n",
      " - 2s - loss: 0.0106 - acc: 0.9958\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.0154 - acc: 0.9944\n",
      "Epoch 89/100\n",
      " - 2s - loss: 0.0161 - acc: 0.9958\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.0070 - acc: 0.9986\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.0168 - acc: 0.9972\n",
      "Epoch 92/100\n",
      " - 2s - loss: 0.0080 - acc: 0.9972\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.0099 - acc: 0.9958\n",
      "Epoch 94/100\n",
      " - 2s - loss: 0.0105 - acc: 0.9958\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.0114 - acc: 0.9972\n",
      "Epoch 97/100\n",
      " - 2s - loss: 0.0071 - acc: 0.9986\n",
      "Epoch 98/100\n",
      " - 2s - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.0167 - acc: 0.9944\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.0111 - acc: 0.9972\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=X_train.toarray().shape[1], activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train.toarray(), to_categorical(y_train, 2), epochs=100, batch_size=10, verbose=2)#, class_weight={1:0.96, 0:0.04})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 50)                2978250   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 2,978,782\n",
      "Trainable params: 2,978,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot metrics\n",
    "plt.plot(history.history['acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4847435276319344\n",
      "0.6158551263337703\n"
     ]
    }
   ],
   "source": [
    "num = metrics.log_loss(y_test.values, model.predict(X_test))\n",
    "\n",
    "#math.exp(-num)\n",
    "print(num)\n",
    "print(math.exp(-num))\n",
    "\n",
    "#print(metrics.accuracy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>000010111</th>\n",
       "      <th>0001</th>\n",
       "      <th>000100</th>\n",
       "      <th>0001001</th>\n",
       "      <th>0001002</th>\n",
       "      <th>0001003</th>\n",
       "      <th>...</th>\n",
       "      <th>ute</th>\n",
       "      <th>uw</th>\n",
       "      <th>x_</th>\n",
       "      <th>xed</th>\n",
       "      <th>ynlzm</th>\n",
       "      <th>z007</th>\n",
       "      <th>zi</th>\n",
       "      <th>zo06</th>\n",
       "      <th></th>\n",
       "      <th>ullnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.010794</td>\n",
       "      <td>0.185563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.015401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>0.079152</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows  56840 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           00       000  0000  00000  000010111      0001  000100  0001001  \\\n",
       "0    0.010794  0.185563   0.0    0.0        0.0  0.000000     0.0      0.0   \n",
       "1    0.000000  0.004759   0.0    0.0        0.0  0.000000     0.0      0.0   \n",
       "2    0.000000  0.000000   0.0    0.0        0.0  0.000000     0.0      0.0   \n",
       "3    0.001792  0.015401   0.0    0.0        0.0  0.000000     0.0      0.0   \n",
       "4    0.000000  0.026197   0.0    0.0        0.0  0.000000     0.0      0.0   \n",
       "..        ...       ...   ...    ...        ...       ...     ...      ...   \n",
       "711  0.000000  0.024976   0.0    0.0        0.0  0.005113     0.0      0.0   \n",
       "712  0.079152  0.011018   0.0    0.0        0.0  0.000000     0.0      0.0   \n",
       "713  0.000000  0.000000   0.0    0.0        0.0  0.000000     0.0      0.0   \n",
       "714  0.001524  0.016549   0.0    0.0        0.0  0.000000     0.0      0.0   \n",
       "715  0.000000  0.000000   0.0    0.0        0.0  0.000000     0.0      0.0   \n",
       "\n",
       "     0001002  0001003  ...  ute  uw  x_  xed  ynlzm  z007  zi  zo06  \\\n",
       "0        0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "1        0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "2        0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "3        0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "4        0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "..       ...      ...  ...   ...  ...  ...   ...     ...    ...  ...    ...   \n",
       "711      0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "712      0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "713      0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "714      0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "715      0.0      0.0  ...   0.0  0.0  0.0   0.0     0.0    0.0  0.0    0.0   \n",
       "\n",
       "        ullnn  \n",
       "0    0.0      0.0  \n",
       "1    0.0      0.0  \n",
       "2    0.0      0.0  \n",
       "3    0.0      0.0  \n",
       "4    0.0      0.0  \n",
       "..   ...      ...  \n",
       "711  0.0      0.0  \n",
       "712  0.0      0.0  \n",
       "713  0.0      0.0  \n",
       "714  0.0      0.0  \n",
       "715  0.0      0.0  \n",
       "\n",
       "[716 rows x 56840 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train\n",
    "pd.DataFrame(X_train.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree \n",
    "\n",
    "Random Forest \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time.time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.log_loss(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \"\"\"\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        #if opts.print_top10 and feature_names is not None:\n",
    "        print(\"top 10 keywords per class:\")\n",
    "        for i, label in enumerate(target_names):\n",
    "            top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "            print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "    \"\"\"\n",
    "    #if opts.print_report:\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred))\n",
    "\n",
    "    #if opts.print_cm:\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None, solver='sag',\n",
      "                tol=0.01)\n",
      "train time: 0.009s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=50, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.006s\n",
      "test time:  0.001s\n",
      "accuracy:   10.074\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.71        24\n",
      "   macro avg       0.42      0.40      0.41        24\n",
      "weighted avg       0.74      0.71      0.73        24\n",
      "\n",
      "confusion matrix:\n",
      "[[17  4]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
      "                            n_jobs=None, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False)\n",
      "train time: 0.004s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "                     weights='uniform')\n",
      "train time: 0.001s\n",
      "test time:  0.004s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "train time: 0.107s\n",
      "test time:  0.008s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50, tol=1e-3), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50, tol=1e-3),\n",
    "         \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 0.014s\n",
      "test time:  0.000s\n",
      "accuracy:   5.756\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.43      0.48      0.45        24\n",
      "weighted avg       0.76      0.83      0.80        24\n",
      "\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.002s\n",
      "test time:  0.000s\n",
      "accuracy:   5.756\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.43      0.48      0.45        24\n",
      "weighted avg       0.76      0.83      0.80        24\n",
      "\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 0.005s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.005s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.006s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.002s\n",
      "test time:  0.001s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.002s\n",
      "accuracy:   5.756\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.43      0.48      0.45        24\n",
      "weighted avg       0.76      0.83      0.80        24\n",
      "\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1, class_prior=None, fit_prior=True, norm=False)\n",
      "train time: 0.002s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "         steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None,\n",
      "                                                     dual=False,\n",
      "                                                     fit_intercept=True,\n",
      "                                                     intercept_scaling=1,\n",
      "                                                     loss='squared_hinge',\n",
      "                                                     max_iter=1000,\n",
      "                                                     multi_class='ovr',\n",
      "                                                     penalty='l1',\n",
      "                                                     random_state=None,\n",
      "                                                     tol=0.001, verbose=0),\n",
      "                                 max_features=None, norm_order=1, prefit=False,\n",
      "                                 threshold=None)),\n",
      "                ('classification',\n",
      "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                           fit_intercept=True, intercept_scaling=1,\n",
      "                           loss='squared_hinge', max_iter=1000,\n",
      "                           multi_class='ovr', penalty='l2', random_state=None,\n",
      "                           tol=0.0001, verbose=0))],\n",
      "         verbose=False)\n",
      "train time: 0.006s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=.1)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
