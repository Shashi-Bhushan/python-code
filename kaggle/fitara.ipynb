{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np  \n",
    "import re  \n",
    "import nltk \n",
    "\n",
    "import time\n",
    "\n",
    "import math\n",
    " \n",
    "import pickle  \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#ROOT_DIR = r'/Users/shabhushan/Desktop/python/python-code/dataset/notracking/participants'\n",
    "ROOT_DIR = r'/home/shashi/Desktop/projects/python-code/dataset/notracking/participants'\n",
    "TRAIN_LABELS = os.path.join(ROOT_DIR, r'train', r'labels', r'labels.csv')\n",
    "TRAIN_TEXT = os.path.join(ROOT_DIR, r'train', r'extracted_data', r'extract_combined.csv')\n",
    "TEST_TEXT = os.path.join(ROOT_DIR, r'test', r'extracted_data', r'extract_combined.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# read in training and testing data\n",
    "# one dataframe for labels another for text features\n",
    "train_labels_df = pd.read_csv(TRAIN_LABELS, usecols=['document_name','is_fitara'])\n",
    "train_text_df = pd.read_csv(TRAIN_TEXT)\n",
    "test_df = pd.read_csv(TEST_TEXT)\n",
    "\n",
    "# combine labels with text features\n",
    "train_df = pd.merge(\n",
    "    train_labels_df, \n",
    "    train_text_df, \n",
    "    on='document_name', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# remove dataframes that are no longer needed from memory \n",
    "del train_labels_df\n",
    "del train_text_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_fitara'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_fitara'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-65542f3eaec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_fitara'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_fitara'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Yes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_fitara'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_fitara'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Yes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_fitara'"
     ]
    }
   ],
   "source": [
    "train_df['is_fitara'] = train_df['is_fitara'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Positive and Negative classes are size 71% and 29% respectively. Hence, no severe class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.713089\n",
       "1    0.286911\n",
       "Name: is_fitara, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# confirm class distribution\n",
    "# is_fitara - yes: ~29%; no: ~71%\n",
    "train_df['is_fitara'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solicitation_id                77\n",
       "contract_award_number         824\n",
       "document_name                   0\n",
       "is_fitara                       0\n",
       "contains_statement_of_work      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(TRAIN_LABELS).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_from_word_list(lst):\n",
    "    temp_set_list = [set(nltk.word_tokenize(words)) for words in lst]\n",
    "\n",
    "    return reduce(lambda x, y: {*x, *y}, temp_set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_no = get_set_from_word_list(train_df_temp)\n",
    "def get_word_frequency(df):\n",
    "    tokenized_words = [nltk.word_tokenize(words) for words in df]\n",
    "    words_list = reduce(lambda x, y: [*x, *y], tokenized_words)\n",
    "\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    vectorizer.fit_transform(words_list)\n",
    "\n",
    "    return pd.DataFrame(vectorizer.vocabulary_.items(), columns=['Text', 'Frequency']).sort_values(by='Frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(train_df, test_df):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', use_idf=True)\n",
    "    X_train = vectorizer.fit_transform(train_df)\n",
    "    \n",
    "    X_test = vectorizer.transform(test_df)\n",
    "\n",
    "    return X_train, X_test, vectorizer.get_feature_names() #pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names()), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_words = [nltk.word_tokenize(words) for words in train_df_temp]\n",
    "#words_list = reduce(lambda x, y: [*x, *y], tokenized_words)\n",
    "\n",
    "#vectorizer = CountVectorizer(stop_words='english')\n",
    "#vectorizer.fit_transform(words_list)\n",
    "\n",
    "#pd.DataFrame(vectorizer.vocabulary_.items(), columns=['Text', 'Frequency']).sort_values(by='Frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_no = train_df[train_df.is_fitara == 0]\n",
    "train_df_yes = train_df[train_df.is_fitara == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 15% of total Records for Ablation\n",
    "ablation = 0.15\n",
    "train_df_no_ablation = train_df_no.loc[0:int(len(train_df_no) * ablation)]\n",
    "train_df_yes_ablation = train_df_yes.loc[0:int(len(train_df_yes) * ablation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ablation = pd.concat([train_df_yes_ablation, train_df_no_ablation]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = train_df_ablation.drop(['is_fitara'], axis=1)\n",
    "y = train_df_ablation['is_fitara']\n",
    "\n",
    "X_train_split, X_test_split, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "#get_tf_idf(train_df_ablation['text'])\n",
    "#train_df_ablation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, feature_names = get_tf_idf(X_train_split['text'], X_test_split['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.2 ms, sys: 5.58 ms, total: 99.8 ms\n",
      "Wall time: 99.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = SVC(kernel='linear', C=100, probability=True, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, x] for x in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/400\n",
      " - 1s - loss: 1.1284 - acc: 0.0833\n",
      "Epoch 2/400\n",
      " - 0s - loss: 0.9528 - acc: 0.0833\n",
      "Epoch 3/400\n",
      " - 0s - loss: 0.8088 - acc: 0.1389\n",
      "Epoch 4/400\n",
      " - 0s - loss: 0.6845 - acc: 0.5417\n",
      "Epoch 5/400\n",
      " - 0s - loss: 0.5927 - acc: 0.8333\n",
      "Epoch 6/400\n",
      " - 0s - loss: 0.5257 - acc: 0.8889\n",
      "Epoch 7/400\n",
      " - 0s - loss: 0.4760 - acc: 0.9167\n",
      "Epoch 8/400\n",
      " - 0s - loss: 0.4381 - acc: 0.9167\n",
      "Epoch 9/400\n",
      " - 0s - loss: 0.4112 - acc: 0.9167\n",
      "Epoch 10/400\n",
      " - 0s - loss: 0.3884 - acc: 0.9167\n",
      "Epoch 11/400\n",
      " - 0s - loss: 0.3720 - acc: 0.9167\n",
      "Epoch 12/400\n",
      " - 0s - loss: 0.3564 - acc: 0.9167\n",
      "Epoch 13/400\n",
      " - 0s - loss: 0.3443 - acc: 0.9167\n",
      "Epoch 14/400\n",
      " - 0s - loss: 0.3328 - acc: 0.9167\n",
      "Epoch 15/400\n",
      " - 0s - loss: 0.3215 - acc: 0.9167\n",
      "Epoch 16/400\n",
      " - 0s - loss: 0.3107 - acc: 0.9167\n",
      "Epoch 17/400\n",
      " - 0s - loss: 0.3007 - acc: 0.9167\n",
      "Epoch 18/400\n",
      " - 0s - loss: 0.2908 - acc: 0.9167\n",
      "Epoch 19/400\n",
      " - 0s - loss: 0.2823 - acc: 0.9167\n",
      "Epoch 20/400\n",
      " - 0s - loss: 0.2743 - acc: 0.9167\n",
      "Epoch 21/400\n",
      " - 0s - loss: 0.2670 - acc: 0.9167\n",
      "Epoch 22/400\n",
      " - 0s - loss: 0.2599 - acc: 0.9167\n",
      "Epoch 23/400\n",
      " - 0s - loss: 0.2532 - acc: 0.9167\n",
      "Epoch 24/400\n",
      " - 0s - loss: 0.2468 - acc: 0.9167\n",
      "Epoch 25/400\n",
      " - 0s - loss: 0.2406 - acc: 0.9167\n",
      "Epoch 26/400\n",
      " - 0s - loss: 0.2353 - acc: 0.9167\n",
      "Epoch 27/400\n",
      " - 0s - loss: 0.2299 - acc: 0.9167\n",
      "Epoch 28/400\n",
      " - 0s - loss: 0.2251 - acc: 0.9167\n",
      "Epoch 29/400\n",
      " - 0s - loss: 0.2205 - acc: 0.9167\n",
      "Epoch 30/400\n",
      " - 0s - loss: 0.2167 - acc: 0.9167\n",
      "Epoch 31/400\n",
      " - 0s - loss: 0.2129 - acc: 0.9167\n",
      "Epoch 32/400\n",
      " - 0s - loss: 0.2097 - acc: 0.9167\n",
      "Epoch 33/400\n",
      " - 0s - loss: 0.2066 - acc: 0.9167\n",
      "Epoch 34/400\n",
      " - 0s - loss: 0.2039 - acc: 0.9167\n",
      "Epoch 35/400\n",
      " - 0s - loss: 0.2012 - acc: 0.9167\n",
      "Epoch 36/400\n",
      " - 0s - loss: 0.1988 - acc: 0.9167\n",
      "Epoch 37/400\n",
      " - 0s - loss: 0.1968 - acc: 0.9167\n",
      "Epoch 38/400\n",
      " - 0s - loss: 0.1945 - acc: 0.9167\n",
      "Epoch 39/400\n",
      " - 0s - loss: 0.1926 - acc: 0.9167\n",
      "Epoch 40/400\n",
      " - 0s - loss: 0.1905 - acc: 0.9167\n",
      "Epoch 41/400\n",
      " - 0s - loss: 0.1885 - acc: 0.9167\n",
      "Epoch 42/400\n",
      " - 0s - loss: 0.1864 - acc: 0.9167\n",
      "Epoch 43/400\n",
      " - 0s - loss: 0.1844 - acc: 0.9167\n",
      "Epoch 44/400\n",
      " - 0s - loss: 0.1819 - acc: 0.9167\n",
      "Epoch 45/400\n",
      " - 0s - loss: 0.1794 - acc: 0.9167\n",
      "Epoch 46/400\n",
      " - 0s - loss: 0.1766 - acc: 0.9167\n",
      "Epoch 47/400\n",
      " - 0s - loss: 0.1752 - acc: 0.9167\n",
      "Epoch 48/400\n",
      " - 0s - loss: 0.1740 - acc: 0.9167\n",
      "Epoch 49/400\n",
      " - 0s - loss: 0.1726 - acc: 0.9167\n",
      "Epoch 50/400\n",
      " - 0s - loss: 0.1715 - acc: 0.9167\n",
      "Epoch 51/400\n",
      " - 0s - loss: 0.1702 - acc: 0.9167\n",
      "Epoch 52/400\n",
      " - 0s - loss: 0.1690 - acc: 0.9167\n",
      "Epoch 53/400\n",
      " - 0s - loss: 0.1679 - acc: 0.9167\n",
      "Epoch 54/400\n",
      " - 0s - loss: 0.1669 - acc: 0.9167\n",
      "Epoch 55/400\n",
      " - 0s - loss: 0.1660 - acc: 0.9167\n",
      "Epoch 56/400\n",
      " - 0s - loss: 0.1652 - acc: 0.9167\n",
      "Epoch 57/400\n",
      " - 0s - loss: 0.1644 - acc: 0.9167\n",
      "Epoch 58/400\n",
      " - 0s - loss: 0.1637 - acc: 0.9167\n",
      "Epoch 59/400\n",
      " - 0s - loss: 0.1629 - acc: 0.9167\n",
      "Epoch 60/400\n",
      " - 0s - loss: 0.1623 - acc: 0.9167\n",
      "Epoch 61/400\n",
      " - 0s - loss: 0.1617 - acc: 0.9167\n",
      "Epoch 62/400\n",
      " - 0s - loss: 0.1610 - acc: 0.9167\n",
      "Epoch 63/400\n",
      " - 0s - loss: 0.1604 - acc: 0.9167\n",
      "Epoch 64/400\n",
      " - 0s - loss: 0.1598 - acc: 0.9167\n",
      "Epoch 65/400\n",
      " - 0s - loss: 0.1594 - acc: 0.9167\n",
      "Epoch 66/400\n",
      " - 0s - loss: 0.1588 - acc: 0.9167\n",
      "Epoch 67/400\n",
      " - 0s - loss: 0.1583 - acc: 0.9167\n",
      "Epoch 68/400\n",
      " - 0s - loss: 0.1578 - acc: 0.9167\n",
      "Epoch 69/400\n",
      " - 0s - loss: 0.1574 - acc: 0.9167\n",
      "Epoch 70/400\n",
      " - 0s - loss: 0.1571 - acc: 0.9167\n",
      "Epoch 71/400\n",
      " - 0s - loss: 0.1568 - acc: 0.9167\n",
      "Epoch 72/400\n",
      " - 0s - loss: 0.1565 - acc: 0.9167\n",
      "Epoch 73/400\n",
      " - 0s - loss: 0.1562 - acc: 0.9167\n",
      "Epoch 74/400\n",
      " - 0s - loss: 0.1560 - acc: 0.9167\n",
      "Epoch 75/400\n",
      " - 0s - loss: 0.1555 - acc: 0.9167\n",
      "Epoch 76/400\n",
      " - 0s - loss: 0.1552 - acc: 0.9167\n",
      "Epoch 77/400\n",
      " - 0s - loss: 0.1550 - acc: 0.9167\n",
      "Epoch 78/400\n",
      " - 0s - loss: 0.1546 - acc: 0.9167\n",
      "Epoch 79/400\n",
      " - 0s - loss: 0.1543 - acc: 0.9167\n",
      "Epoch 80/400\n",
      " - 0s - loss: 0.1541 - acc: 0.9167\n",
      "Epoch 81/400\n",
      " - 0s - loss: 0.1538 - acc: 0.9167\n",
      "Epoch 82/400\n",
      " - 0s - loss: 0.1535 - acc: 0.9167\n",
      "Epoch 83/400\n",
      " - 0s - loss: 0.1532 - acc: 0.9167\n",
      "Epoch 84/400\n",
      " - 0s - loss: 0.1530 - acc: 0.9167\n",
      "Epoch 85/400\n",
      " - 0s - loss: 0.1528 - acc: 0.9167\n",
      "Epoch 86/400\n",
      " - 0s - loss: 0.1525 - acc: 0.9167\n",
      "Epoch 87/400\n",
      " - 0s - loss: 0.1523 - acc: 0.9167\n",
      "Epoch 88/400\n",
      " - 0s - loss: 0.1522 - acc: 0.9167\n",
      "Epoch 89/400\n",
      " - 0s - loss: 0.1519 - acc: 0.9167\n",
      "Epoch 90/400\n",
      " - 0s - loss: 0.1517 - acc: 0.9167\n",
      "Epoch 91/400\n",
      " - 0s - loss: 0.1515 - acc: 0.9167\n",
      "Epoch 92/400\n",
      " - 0s - loss: 0.1514 - acc: 0.9167\n",
      "Epoch 93/400\n",
      " - 0s - loss: 0.1512 - acc: 0.9167\n",
      "Epoch 94/400\n",
      " - 0s - loss: 0.1510 - acc: 0.9167\n",
      "Epoch 95/400\n",
      " - 0s - loss: 0.1509 - acc: 0.9167\n",
      "Epoch 96/400\n",
      " - 0s - loss: 0.1507 - acc: 0.9167\n",
      "Epoch 97/400\n",
      " - 0s - loss: 0.1505 - acc: 0.9167\n",
      "Epoch 98/400\n",
      " - 0s - loss: 0.1505 - acc: 0.9167\n",
      "Epoch 99/400\n",
      " - 0s - loss: 0.1503 - acc: 0.9167\n",
      "Epoch 100/400\n",
      " - 0s - loss: 0.1503 - acc: 0.9167\n",
      "Epoch 101/400\n",
      " - 0s - loss: 0.1503 - acc: 0.9167\n",
      "Epoch 102/400\n",
      " - 0s - loss: 0.1501 - acc: 0.9167\n",
      "Epoch 103/400\n",
      " - 0s - loss: 0.1500 - acc: 0.9167\n",
      "Epoch 104/400\n",
      " - 0s - loss: 0.1499 - acc: 0.9167\n",
      "Epoch 105/400\n",
      " - 0s - loss: 0.1498 - acc: 0.9167\n",
      "Epoch 106/400\n",
      " - 0s - loss: 0.1497 - acc: 0.9167\n",
      "Epoch 107/400\n",
      " - 0s - loss: 0.1496 - acc: 0.9167\n",
      "Epoch 108/400\n",
      " - 0s - loss: 0.1494 - acc: 0.9167\n",
      "Epoch 109/400\n",
      " - 0s - loss: 0.1493 - acc: 0.9167\n",
      "Epoch 110/400\n",
      " - 0s - loss: 0.1492 - acc: 0.9167\n",
      "Epoch 111/400\n",
      " - 0s - loss: 0.1492 - acc: 0.9167\n",
      "Epoch 112/400\n",
      " - 0s - loss: 0.1491 - acc: 0.9167\n",
      "Epoch 113/400\n",
      " - 0s - loss: 0.1491 - acc: 0.9167\n",
      "Epoch 114/400\n",
      " - 0s - loss: 0.1491 - acc: 0.9167\n",
      "Epoch 115/400\n",
      " - 0s - loss: 0.1490 - acc: 0.9167\n",
      "Epoch 116/400\n",
      " - 0s - loss: 0.1489 - acc: 0.9167\n",
      "Epoch 117/400\n",
      " - 0s - loss: 0.1488 - acc: 0.9167\n",
      "Epoch 118/400\n",
      " - 0s - loss: 0.1487 - acc: 0.9167\n",
      "Epoch 119/400\n",
      " - 0s - loss: 0.1486 - acc: 0.9167\n",
      "Epoch 120/400\n",
      " - 0s - loss: 0.1485 - acc: 0.9167\n",
      "Epoch 121/400\n",
      " - 0s - loss: 0.1485 - acc: 0.9167\n",
      "Epoch 122/400\n",
      " - 0s - loss: 0.1484 - acc: 0.9167\n",
      "Epoch 123/400\n",
      " - 0s - loss: 0.1483 - acc: 0.9167\n",
      "Epoch 124/400\n",
      " - 0s - loss: 0.1482 - acc: 0.9167\n",
      "Epoch 125/400\n",
      " - 0s - loss: 0.1481 - acc: 0.9167\n",
      "Epoch 126/400\n",
      " - 0s - loss: 0.1481 - acc: 0.9167\n",
      "Epoch 127/400\n",
      " - 0s - loss: 0.1480 - acc: 0.9167\n",
      "Epoch 128/400\n",
      " - 0s - loss: 0.1479 - acc: 0.9167\n",
      "Epoch 129/400\n",
      " - 0s - loss: 0.1478 - acc: 0.9167\n",
      "Epoch 130/400\n",
      " - 0s - loss: 0.1477 - acc: 0.9167\n",
      "Epoch 131/400\n",
      " - 0s - loss: 0.1476 - acc: 0.9167\n",
      "Epoch 132/400\n",
      " - 0s - loss: 0.1476 - acc: 0.9167\n",
      "Epoch 133/400\n",
      " - 0s - loss: 0.1470 - acc: 0.9167\n",
      "Epoch 134/400\n",
      " - 0s - loss: 0.1465 - acc: 0.9167\n",
      "Epoch 135/400\n",
      " - 0s - loss: 0.1453 - acc: 0.9167\n",
      "Epoch 136/400\n",
      " - 0s - loss: 0.1401 - acc: 0.9167\n",
      "Epoch 137/400\n",
      " - 0s - loss: 0.1376 - acc: 0.9167\n",
      "Epoch 138/400\n",
      " - 0s - loss: 0.1296 - acc: 0.9167\n",
      "Epoch 139/400\n",
      " - 0s - loss: 0.1289 - acc: 0.9167\n",
      "Epoch 140/400\n",
      " - 0s - loss: 0.1288 - acc: 0.9167\n",
      "Epoch 141/400\n",
      " - 0s - loss: 0.1289 - acc: 0.9167\n",
      "Epoch 142/400\n",
      " - 0s - loss: 0.1283 - acc: 0.9167\n",
      "Epoch 143/400\n",
      " - 0s - loss: 0.1277 - acc: 0.9167\n",
      "Epoch 144/400\n",
      " - 0s - loss: 0.1271 - acc: 0.9167\n",
      "Epoch 145/400\n",
      " - 0s - loss: 0.1267 - acc: 0.9167\n",
      "Epoch 146/400\n",
      " - 0s - loss: 0.1265 - acc: 0.9167\n",
      "Epoch 147/400\n",
      " - 0s - loss: 0.1261 - acc: 0.9167\n",
      "Epoch 148/400\n",
      " - 0s - loss: 0.1260 - acc: 0.9167\n",
      "Epoch 149/400\n",
      " - 0s - loss: 0.1257 - acc: 0.9167\n",
      "Epoch 150/400\n",
      " - 0s - loss: 0.1255 - acc: 0.9167\n",
      "Epoch 151/400\n",
      " - 0s - loss: 0.1254 - acc: 0.9167\n",
      "Epoch 152/400\n",
      " - 0s - loss: 0.1252 - acc: 0.9167\n",
      "Epoch 153/400\n",
      " - 0s - loss: 0.1251 - acc: 0.9167\n",
      "Epoch 154/400\n",
      " - 0s - loss: 0.1249 - acc: 0.9167\n",
      "Epoch 155/400\n",
      " - 0s - loss: 0.1248 - acc: 0.9167\n",
      "Epoch 156/400\n",
      " - 0s - loss: 0.1246 - acc: 0.9167\n",
      "Epoch 157/400\n",
      " - 0s - loss: 0.1245 - acc: 0.9167\n",
      "Epoch 158/400\n",
      " - 0s - loss: 0.1244 - acc: 0.9167\n",
      "Epoch 159/400\n",
      " - 0s - loss: 0.1242 - acc: 0.9167\n",
      "Epoch 160/400\n",
      " - 0s - loss: 0.1241 - acc: 0.9167\n",
      "Epoch 161/400\n",
      " - 0s - loss: 0.1240 - acc: 0.9167\n",
      "Epoch 162/400\n",
      " - 0s - loss: 0.1239 - acc: 0.9167\n",
      "Epoch 163/400\n",
      " - 0s - loss: 0.1237 - acc: 0.9167\n",
      "Epoch 164/400\n",
      " - 0s - loss: 0.1236 - acc: 0.9167\n",
      "Epoch 165/400\n",
      " - 0s - loss: 0.1235 - acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/400\n",
      " - 0s - loss: 0.1234 - acc: 0.9167\n",
      "Epoch 167/400\n",
      " - 0s - loss: 0.1233 - acc: 0.9167\n",
      "Epoch 168/400\n",
      " - 0s - loss: 0.1232 - acc: 0.9167\n",
      "Epoch 169/400\n",
      " - 0s - loss: 0.1231 - acc: 0.9167\n",
      "Epoch 170/400\n",
      " - 0s - loss: 0.1230 - acc: 0.9167\n",
      "Epoch 171/400\n",
      " - 0s - loss: 0.1229 - acc: 0.9167\n",
      "Epoch 172/400\n",
      " - 0s - loss: 0.1228 - acc: 0.9167\n",
      "Epoch 173/400\n",
      " - 0s - loss: 0.1227 - acc: 0.9167\n",
      "Epoch 174/400\n",
      " - 0s - loss: 0.1226 - acc: 0.9167\n",
      "Epoch 175/400\n",
      " - 0s - loss: 0.1225 - acc: 0.9167\n",
      "Epoch 176/400\n",
      " - 0s - loss: 0.1224 - acc: 0.9167\n",
      "Epoch 177/400\n",
      " - 0s - loss: 0.1223 - acc: 0.9167\n",
      "Epoch 178/400\n",
      " - 0s - loss: 0.1223 - acc: 0.9167\n",
      "Epoch 179/400\n",
      " - 0s - loss: 0.1222 - acc: 0.9167\n",
      "Epoch 180/400\n",
      " - 0s - loss: 0.1221 - acc: 0.9167\n",
      "Epoch 181/400\n",
      " - 0s - loss: 0.1220 - acc: 0.9167\n",
      "Epoch 182/400\n",
      " - 0s - loss: 0.1219 - acc: 0.9167\n",
      "Epoch 183/400\n",
      " - 0s - loss: 0.1219 - acc: 0.9167\n",
      "Epoch 184/400\n",
      " - 0s - loss: 0.1218 - acc: 0.9167\n",
      "Epoch 185/400\n",
      " - 0s - loss: 0.1217 - acc: 0.9167\n",
      "Epoch 186/400\n",
      " - 0s - loss: 0.1216 - acc: 0.9167\n",
      "Epoch 187/400\n",
      " - 0s - loss: 0.1216 - acc: 0.9167\n",
      "Epoch 188/400\n",
      " - 0s - loss: 0.1215 - acc: 0.9167\n",
      "Epoch 189/400\n",
      " - 0s - loss: 0.1214 - acc: 0.9167\n",
      "Epoch 190/400\n",
      " - 0s - loss: 0.1214 - acc: 0.9167\n",
      "Epoch 191/400\n",
      " - 0s - loss: 0.1213 - acc: 0.9167\n",
      "Epoch 192/400\n",
      " - 0s - loss: 0.1212 - acc: 0.9167\n",
      "Epoch 193/400\n",
      " - 0s - loss: 0.1212 - acc: 0.9167\n",
      "Epoch 194/400\n",
      " - 0s - loss: 0.1211 - acc: 0.9167\n",
      "Epoch 195/400\n",
      " - 0s - loss: 0.1210 - acc: 0.9167\n",
      "Epoch 196/400\n",
      " - 0s - loss: 0.1210 - acc: 0.9167\n",
      "Epoch 197/400\n",
      " - 0s - loss: 0.1209 - acc: 0.9167\n",
      "Epoch 198/400\n",
      " - 0s - loss: 0.1209 - acc: 0.9167\n",
      "Epoch 199/400\n",
      " - 0s - loss: 0.1208 - acc: 0.9167\n",
      "Epoch 200/400\n",
      " - 0s - loss: 0.1207 - acc: 0.9167\n",
      "Epoch 201/400\n",
      " - 0s - loss: 0.1207 - acc: 0.9167\n",
      "Epoch 202/400\n",
      " - 0s - loss: 0.1206 - acc: 0.9167\n",
      "Epoch 203/400\n",
      " - 0s - loss: 0.1206 - acc: 0.9167\n",
      "Epoch 204/400\n",
      " - 0s - loss: 0.1205 - acc: 0.9167\n",
      "Epoch 205/400\n",
      " - 0s - loss: 0.1205 - acc: 0.9167\n",
      "Epoch 206/400\n",
      " - 0s - loss: 0.1204 - acc: 0.9167\n",
      "Epoch 207/400\n",
      " - 0s - loss: 0.1204 - acc: 0.9167\n",
      "Epoch 208/400\n",
      " - 0s - loss: 0.1203 - acc: 0.9167\n",
      "Epoch 209/400\n",
      " - 0s - loss: 0.1203 - acc: 0.9167\n",
      "Epoch 210/400\n",
      " - 0s - loss: 0.1202 - acc: 0.9167\n",
      "Epoch 211/400\n",
      " - 0s - loss: 0.1202 - acc: 0.9167\n",
      "Epoch 212/400\n",
      " - 0s - loss: 0.1201 - acc: 0.9167\n",
      "Epoch 213/400\n",
      " - 0s - loss: 0.1201 - acc: 0.9167\n",
      "Epoch 214/400\n",
      " - 0s - loss: 0.1200 - acc: 0.9167\n",
      "Epoch 215/400\n",
      " - 0s - loss: 0.1200 - acc: 0.9167\n",
      "Epoch 216/400\n",
      " - 0s - loss: 0.1200 - acc: 0.9167\n",
      "Epoch 217/400\n",
      " - 0s - loss: 0.1199 - acc: 0.9167\n",
      "Epoch 218/400\n",
      " - 0s - loss: 0.1199 - acc: 0.9167\n",
      "Epoch 219/400\n",
      " - 0s - loss: 0.1198 - acc: 0.9167\n",
      "Epoch 220/400\n",
      " - 0s - loss: 0.1198 - acc: 0.9167\n",
      "Epoch 221/400\n",
      " - 0s - loss: 0.1197 - acc: 0.9167\n",
      "Epoch 222/400\n",
      " - 0s - loss: 0.1197 - acc: 0.9167\n",
      "Epoch 223/400\n",
      " - 0s - loss: 0.1197 - acc: 0.9167\n",
      "Epoch 224/400\n",
      " - 0s - loss: 0.1196 - acc: 0.9167\n",
      "Epoch 225/400\n",
      " - 0s - loss: 0.1196 - acc: 0.9167\n",
      "Epoch 226/400\n",
      " - 0s - loss: 0.1195 - acc: 0.9167\n",
      "Epoch 227/400\n",
      " - 0s - loss: 0.1195 - acc: 0.9167\n",
      "Epoch 228/400\n",
      " - 0s - loss: 0.1195 - acc: 0.9167\n",
      "Epoch 229/400\n",
      " - 0s - loss: 0.1194 - acc: 0.9167\n",
      "Epoch 230/400\n",
      " - 0s - loss: 0.1194 - acc: 0.9167\n",
      "Epoch 231/400\n",
      " - 0s - loss: 0.1194 - acc: 0.9167\n",
      "Epoch 232/400\n",
      " - 0s - loss: 0.1193 - acc: 0.9167\n",
      "Epoch 233/400\n",
      " - 0s - loss: 0.1193 - acc: 0.9167\n",
      "Epoch 234/400\n",
      " - 0s - loss: 0.1193 - acc: 0.9167\n",
      "Epoch 235/400\n",
      " - 0s - loss: 0.1192 - acc: 0.9167\n",
      "Epoch 236/400\n",
      " - 0s - loss: 0.1192 - acc: 0.9167\n",
      "Epoch 237/400\n",
      " - 0s - loss: 0.1192 - acc: 0.9167\n",
      "Epoch 238/400\n",
      " - 0s - loss: 0.1191 - acc: 0.9167\n",
      "Epoch 239/400\n",
      " - 0s - loss: 0.1191 - acc: 0.9167\n",
      "Epoch 240/400\n",
      " - 0s - loss: 0.1191 - acc: 0.9167\n",
      "Epoch 241/400\n",
      " - 0s - loss: 0.1190 - acc: 0.9167\n",
      "Epoch 242/400\n",
      " - 0s - loss: 0.1190 - acc: 0.9167\n",
      "Epoch 243/400\n",
      " - 0s - loss: 0.1190 - acc: 0.9167\n",
      "Epoch 244/400\n",
      " - 0s - loss: 0.1189 - acc: 0.9167\n",
      "Epoch 245/400\n",
      " - 0s - loss: 0.1189 - acc: 0.9167\n",
      "Epoch 246/400\n",
      " - 0s - loss: 0.1189 - acc: 0.9167\n",
      "Epoch 247/400\n",
      " - 0s - loss: 0.1188 - acc: 0.9167\n",
      "Epoch 248/400\n",
      " - 0s - loss: 0.1188 - acc: 0.9167\n",
      "Epoch 249/400\n",
      " - 0s - loss: 0.1188 - acc: 0.9167\n",
      "Epoch 250/400\n",
      " - 0s - loss: 0.1188 - acc: 0.9167\n",
      "Epoch 251/400\n",
      " - 0s - loss: 0.1187 - acc: 0.9167\n",
      "Epoch 252/400\n",
      " - 0s - loss: 0.1187 - acc: 0.9167\n",
      "Epoch 253/400\n",
      " - 0s - loss: 0.1187 - acc: 0.9167\n",
      "Epoch 254/400\n",
      " - 0s - loss: 0.1187 - acc: 0.9167\n",
      "Epoch 255/400\n",
      " - 0s - loss: 0.1186 - acc: 0.9167\n",
      "Epoch 256/400\n",
      " - 0s - loss: 0.1186 - acc: 0.9167\n",
      "Epoch 257/400\n",
      " - 0s - loss: 0.1186 - acc: 0.9167\n",
      "Epoch 258/400\n",
      " - 0s - loss: 0.1186 - acc: 0.9167\n",
      "Epoch 259/400\n",
      " - 0s - loss: 0.1185 - acc: 0.9167\n",
      "Epoch 260/400\n",
      " - 0s - loss: 0.1185 - acc: 0.9167\n",
      "Epoch 261/400\n",
      " - 0s - loss: 0.1185 - acc: 0.9167\n",
      "Epoch 262/400\n",
      " - 0s - loss: 0.1185 - acc: 0.9167\n",
      "Epoch 263/400\n",
      " - 0s - loss: 0.1184 - acc: 0.9167\n",
      "Epoch 264/400\n",
      " - 0s - loss: 0.1184 - acc: 0.9167\n",
      "Epoch 265/400\n",
      " - 0s - loss: 0.1184 - acc: 0.9167\n",
      "Epoch 266/400\n",
      " - 0s - loss: 0.1184 - acc: 0.9167\n",
      "Epoch 267/400\n",
      " - 0s - loss: 0.1183 - acc: 0.9167\n",
      "Epoch 268/400\n",
      " - 0s - loss: 0.1183 - acc: 0.9167\n",
      "Epoch 269/400\n",
      " - 0s - loss: 0.1183 - acc: 0.9167\n",
      "Epoch 270/400\n",
      " - 0s - loss: 0.1183 - acc: 0.9167\n",
      "Epoch 271/400\n",
      " - 0s - loss: 0.1183 - acc: 0.9167\n",
      "Epoch 272/400\n",
      " - 0s - loss: 0.1182 - acc: 0.9167\n",
      "Epoch 273/400\n",
      " - 0s - loss: 0.1182 - acc: 0.9167\n",
      "Epoch 274/400\n",
      " - 0s - loss: 0.1182 - acc: 0.9167\n",
      "Epoch 275/400\n",
      " - 0s - loss: 0.1182 - acc: 0.9167\n",
      "Epoch 276/400\n",
      " - 0s - loss: 0.1181 - acc: 0.9167\n",
      "Epoch 277/400\n",
      " - 0s - loss: 0.1181 - acc: 0.9167\n",
      "Epoch 278/400\n",
      " - 0s - loss: 0.1181 - acc: 0.9167\n",
      "Epoch 279/400\n",
      " - 0s - loss: 0.1181 - acc: 0.9167\n",
      "Epoch 280/400\n",
      " - 0s - loss: 0.1181 - acc: 0.9167\n",
      "Epoch 281/400\n",
      " - 0s - loss: 0.1180 - acc: 0.9167\n",
      "Epoch 282/400\n",
      " - 0s - loss: 0.1180 - acc: 0.9167\n",
      "Epoch 283/400\n",
      " - 0s - loss: 0.1180 - acc: 0.9167\n",
      "Epoch 284/400\n",
      " - 0s - loss: 0.1180 - acc: 0.9167\n",
      "Epoch 285/400\n",
      " - 0s - loss: 0.1180 - acc: 0.9167\n",
      "Epoch 286/400\n",
      " - 0s - loss: 0.1180 - acc: 0.9167\n",
      "Epoch 287/400\n",
      " - 0s - loss: 0.1179 - acc: 0.9167\n",
      "Epoch 288/400\n",
      " - 0s - loss: 0.1179 - acc: 0.9167\n",
      "Epoch 289/400\n",
      " - 0s - loss: 0.1179 - acc: 0.9167\n",
      "Epoch 290/400\n",
      " - 0s - loss: 0.1179 - acc: 0.9167\n",
      "Epoch 291/400\n",
      " - 0s - loss: 0.1179 - acc: 0.9167\n",
      "Epoch 292/400\n",
      " - 0s - loss: 0.1179 - acc: 0.9167\n",
      "Epoch 293/400\n",
      " - 0s - loss: 0.1178 - acc: 0.9167\n",
      "Epoch 294/400\n",
      " - 0s - loss: 0.1178 - acc: 0.9167\n",
      "Epoch 295/400\n",
      " - 0s - loss: 0.1178 - acc: 0.9167\n",
      "Epoch 296/400\n",
      " - 0s - loss: 0.1178 - acc: 0.9167\n",
      "Epoch 297/400\n",
      " - 0s - loss: 0.1178 - acc: 0.9167\n",
      "Epoch 298/400\n",
      " - 0s - loss: 0.1178 - acc: 0.9167\n",
      "Epoch 299/400\n",
      " - 0s - loss: 0.1177 - acc: 0.9167\n",
      "Epoch 300/400\n",
      " - 0s - loss: 0.1177 - acc: 0.9167\n",
      "Epoch 301/400\n",
      " - 0s - loss: 0.1177 - acc: 0.9167\n",
      "Epoch 302/400\n",
      " - 0s - loss: 0.1177 - acc: 0.9167\n",
      "Epoch 303/400\n",
      " - 0s - loss: 0.1177 - acc: 0.9167\n",
      "Epoch 304/400\n",
      " - 0s - loss: 0.1177 - acc: 0.9167\n",
      "Epoch 305/400\n",
      " - 0s - loss: 0.1176 - acc: 0.9167\n",
      "Epoch 306/400\n",
      " - 0s - loss: 0.1176 - acc: 0.9167\n",
      "Epoch 307/400\n",
      " - 0s - loss: 0.1176 - acc: 0.9167\n",
      "Epoch 308/400\n",
      " - 0s - loss: 0.1176 - acc: 0.9167\n",
      "Epoch 309/400\n",
      " - 0s - loss: 0.1176 - acc: 0.9167\n",
      "Epoch 310/400\n",
      " - 0s - loss: 0.1176 - acc: 0.9167\n",
      "Epoch 311/400\n",
      " - 0s - loss: 0.1177 - acc: 0.9167\n",
      "Epoch 312/400\n",
      " - 0s - loss: 0.1176 - acc: 0.9167\n",
      "Epoch 313/400\n",
      " - 0s - loss: 0.1178 - acc: 0.9167\n",
      "Epoch 314/400\n",
      " - 0s - loss: 0.1176 - acc: 0.9167\n",
      "Epoch 315/400\n",
      " - 0s - loss: 0.1175 - acc: 0.9167\n",
      "Epoch 316/400\n",
      " - 0s - loss: 0.1175 - acc: 0.9167\n",
      "Epoch 317/400\n",
      " - 0s - loss: 0.1175 - acc: 0.9167\n",
      "Epoch 318/400\n",
      " - 0s - loss: 0.1175 - acc: 0.9167\n",
      "Epoch 319/400\n",
      " - 0s - loss: 0.1175 - acc: 0.9167\n",
      "Epoch 320/400\n",
      " - 0s - loss: 0.1175 - acc: 0.9167\n",
      "Epoch 321/400\n",
      " - 0s - loss: 0.1174 - acc: 0.9167\n",
      "Epoch 322/400\n",
      " - 0s - loss: 0.1175 - acc: 0.9167\n",
      "Epoch 323/400\n",
      " - 0s - loss: 0.1174 - acc: 0.9167\n",
      "Epoch 324/400\n",
      " - 0s - loss: 0.1174 - acc: 0.9167\n",
      "Epoch 325/400\n",
      " - 0s - loss: 0.1174 - acc: 0.9167\n",
      "Epoch 326/400\n",
      " - 0s - loss: 0.1174 - acc: 0.9167\n",
      "Epoch 327/400\n",
      " - 0s - loss: 0.1173 - acc: 0.9167\n",
      "Epoch 328/400\n",
      " - 0s - loss: 0.1173 - acc: 0.9167\n",
      "Epoch 329/400\n",
      " - 0s - loss: 0.1173 - acc: 0.9167\n",
      "Epoch 330/400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-02e559447d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# plot metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     90\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3500\u001b[0m     \"\"\"\n\u001b[1;32m   3501\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3502\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m     \"\"\"\n\u001b[0;32m-> 3385\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3386\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(35, input_dim=X_train.T.toarray().shape[0]))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train.toarray(), y_t, epochs=400, batch_size=10, verbose=2)\n",
    "\n",
    "# plot metrics\n",
    "pyplot.plot(history.history['acc'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.653460114513189"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test.values)\n",
    "print(pred)\n",
    "#print(pred_proba)\n",
    "\n",
    "num = metrics.log_loss(y_test.values, pred_proba)\n",
    "\n",
    "\n",
    "math.exp(-num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time.time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time.time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.log_loss(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \"\"\"\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        #if opts.print_top10 and feature_names is not None:\n",
    "        print(\"top 10 keywords per class:\")\n",
    "        for i, label in enumerate(target_names):\n",
    "            top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "            print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "    \"\"\"\n",
    "    #if opts.print_report:\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred))\n",
    "\n",
    "    #if opts.print_cm:\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None, solver='sag',\n",
      "                tol=0.01)\n",
      "train time: 0.009s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=50, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.006s\n",
      "test time:  0.001s\n",
      "accuracy:   10.074\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.71        24\n",
      "   macro avg       0.42      0.40      0.41        24\n",
      "weighted avg       0.74      0.71      0.73        24\n",
      "\n",
      "confusion matrix:\n",
      "[[17  4]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
      "                            n_jobs=None, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False)\n",
      "train time: 0.004s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "                     weights='uniform')\n",
      "train time: 0.001s\n",
      "test time:  0.004s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "train time: 0.107s\n",
      "test time:  0.008s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50, tol=1e-3), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50, tol=1e-3),\n",
    "         \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 0.014s\n",
      "test time:  0.000s\n",
      "accuracy:   5.756\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.43      0.48      0.45        24\n",
      "weighted avg       0.76      0.83      0.80        24\n",
      "\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.002s\n",
      "test time:  0.000s\n",
      "accuracy:   5.756\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.43      0.48      0.45        24\n",
      "weighted avg       0.76      0.83      0.80        24\n",
      "\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 0.005s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.005s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.006s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.002s\n",
      "test time:  0.001s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.000s\n",
      "accuracy:   7.196\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.43      0.45      0.44        24\n",
      "weighted avg       0.76      0.79      0.77        24\n",
      "\n",
      "confusion matrix:\n",
      "[[19  2]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.002s\n",
      "accuracy:   5.756\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83        24\n",
      "   macro avg       0.43      0.48      0.45        24\n",
      "weighted avg       0.76      0.83      0.80        24\n",
      "\n",
      "confusion matrix:\n",
      "[[20  1]\n",
      " [ 3  0]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1, class_prior=None, fit_prior=True, norm=False)\n",
      "train time: 0.002s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "         steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None,\n",
      "                                                     dual=False,\n",
      "                                                     fit_intercept=True,\n",
      "                                                     intercept_scaling=1,\n",
      "                                                     loss='squared_hinge',\n",
      "                                                     max_iter=1000,\n",
      "                                                     multi_class='ovr',\n",
      "                                                     penalty='l1',\n",
      "                                                     random_state=None,\n",
      "                                                     tol=0.001, verbose=0),\n",
      "                                 max_features=None, norm_order=1, prefit=False,\n",
      "                                 threshold=None)),\n",
      "                ('classification',\n",
      "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                           fit_intercept=True, intercept_scaling=1,\n",
      "                           loss='squared_hinge', max_iter=1000,\n",
      "                           multi_class='ovr', penalty='l2', random_state=None,\n",
      "                           tol=0.0001, verbose=0))],\n",
      "         verbose=False)\n",
      "train time: 0.006s\n",
      "test time:  0.000s\n",
      "accuracy:   4.317\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.44      0.50      0.47        24\n",
      "weighted avg       0.77      0.88      0.82        24\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0]\n",
      " [ 3  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=.1)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
