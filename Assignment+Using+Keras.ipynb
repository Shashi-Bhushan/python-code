{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you'll implement a L-layer deep model on MNIST dataset using Keras. The MNIST dataset contains tens of thousands of scanned images of handwritten digits, together with their correct classifications. MNIST's name comes from the fact that it is a modified subset of two data sets collected by NIST, the United States' National Institute of Standards and Technology.<br>\n",
    "<br>\n",
    "<br>\n",
    "To use Keras, you'll need to install Keras and Tensorflow.\n",
    "<br>\n",
    "Please run the following commands if you don't have Keras and TensorFlow already installed.\n",
    "<br>\n",
    "1. ! pip install TensorFlow\n",
    "<br>\n",
    "2. ! pip install keras\n",
    "<br>\n",
    "3. ! pip install msgpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import scipy\n",
    "\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras import regularizers\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset we use here is 'mnist.pkl.gz' which is divided into training, validation and test data. The following function <i> load_data() </i> unpacks the file and extracts the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    f = gzip.open('dataset/notracking/mnist.pkl.gz', 'rb')\n",
    "    f.seek(0)\n",
    "    training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 8, 4, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature dataset is:[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "The target dataset is:[5 0 4 ... 8 4 8]\n",
      "The number of examples in the training dataset is:50000\n",
      "The number of points in a single input is:784\n"
     ]
    }
   ],
   "source": [
    "print(\"The feature dataset is:\" + str(training_data[0]))\n",
    "print(\"The target dataset is:\" + str(training_data[1]))\n",
    "print(\"The number of examples in the training dataset is:\" + str(len(training_data[0])))\n",
    "print(\"The number of points in a single input is:\" + str(len(training_data[0][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as discussed earlier in the lectures, the target variable is converted to a one hot matrix. We use the function <i> one_hot </i> to convert the target dataset to one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(j):\n",
    "    # input is the target dataset of shape (1, m) where m is the number of data points\n",
    "    # returns a 2 dimensional array of shape (10, m) where each target value is converted to a one hot encoding\n",
    "    # Look at the next block of code for a better understanding of one hot encoding\n",
    "    n = j.shape[0]\n",
    "    new_array = np.zeros((10, n))\n",
    "    index = 0\n",
    "    for res in j:\n",
    "        new_array[res][index] = 1.0\n",
    "        index = index + 1\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7])\n",
    "one_hot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrapper():\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    \n",
    "    training_inputs = np.array(tr_d[0][:]).T\n",
    "    training_results = np.array(tr_d[1][:])\n",
    "    train_set_y = one_hot(training_results)\n",
    "    \n",
    "    validation_inputs = np.array(va_d[0][:]).T\n",
    "    validation_results = np.array(va_d[1][:])\n",
    "    validation_set_y = one_hot(validation_results)\n",
    "    \n",
    "    test_inputs = np.array(te_d[0][:]).T\n",
    "    test_results = np.array(te_d[1][:])\n",
    "    test_set_y = one_hot(test_results)\n",
    "    \n",
    "    return (training_inputs, train_set_y, validation_inputs, validation_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x, train_set_y, test_set_x, test_set_y = data_wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementing in Keras, the input training and input target dataset are supposed to have shape (m, n) where m is the number of training samples and n is the number of parts in a single input.\n",
    "<br> Hence, let create the desired dataset shapes by taking transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x.T\n",
    "train_set_y = train_set_y.T\n",
    "test_set_x = test_set_x.T\n",
    "test_set_y = test_set_y.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if the datasets are in the desired shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape: (50000, 784) <class 'numpy.ndarray'>\n",
      "train_set_y shape: (50000, 10) <class 'numpy.ndarray'>\n",
      "test_set_x shape: (10000, 784)\n",
      "test_set_y shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (f\"train_set_x shape: {train_set_x.shape} {type(train_set_x)}\")\n",
    "print (f\"train_set_y shape: {train_set_y.shape} {type(train_set_y)}\")\n",
    "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us visualise the dataset. Feel free to change the index to see if the training data has been correctly tagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4a0c6c55c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index  = 1800\n",
    "k = train_set_x[index,:]\n",
    "k = k.reshape((28, 28))\n",
    "plt.title('Label is {}'.format(training_data[1][index]))\n",
    "plt.imshow(k, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a framework. So, to implement a neural network model in Keras, we first create an instance of Sequential(). <br>\n",
    "The Sequential model is a linear stack of layers. We then keep adding Dense layers that are fully connected layers as we desire.<br><br>\n",
    "We have included Dropout using <i> nn_model.add(Dropout(0.3)) </i> <br><br>\n",
    "We can also include regularization using the command <br> <i> nn_model.add(Dense(21, activation='relu', kernel_regularizer=regularizers.l2(0.01))) </i> <br>instead of <br> <i> nn_model.add(Dense(21, activation='relu')) </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 17:51:59.477902 139957738956608 deprecation_wrapper.py:119] From /home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0823 17:51:59.507199 139957738956608 deprecation_wrapper.py:119] From /home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0823 17:51:59.508539 139957738956608 deprecation_wrapper.py:119] From /home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0823 17:51:59.516870 139957738956608 deprecation_wrapper.py:119] From /home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0823 17:51:59.521125 139957738956608 deprecation.py:506] From /home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(35, input_dim=784, activation='relu'))\n",
    "nn_model.add(Dropout(0.3))\n",
    "nn_model.add(Dense(21, activation = 'relu'))\n",
    "nn_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the model on the training datasets, we compile the model in which we define various things like the loss function, the optimizer and the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 17:51:59.548385 139957738956608 deprecation_wrapper.py:119] From /home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0823 17:51:59.562119 139957738956608 deprecation_wrapper.py:119] From /home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to fit the model on the training input and training target dataset, we run the following command using a minibatch of size 10 and 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 17:51:59.626388 139957738956608 deprecation.py:323] From /home/shashi/.local/share/virtualenvs/python-code-gqSjhHCu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.5012 - acc: 0.8453\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.3248 - acc: 0.9000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.2870 - acc: 0.9121\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.2641 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.2519 - acc: 0.9217\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.2438 - acc: 0.9228\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.2320 - acc: 0.9266\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.2246 - acc: 0.9293\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 3s 63us/step - loss: 0.2238 - acc: 0.9293\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.2214 - acc: 0.9293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a0c632048>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(train_set_x, train_set_y, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 0s 8us/step\n",
      "\n",
      "acc: 96.78%\n"
     ]
    }
   ],
   "source": [
    "scores_train = nn_model.evaluate(train_set_x, train_set_y)\n",
    "print(\"\\n%s: %.2f%%\" % (nn_model.metrics_names[1], scores_train[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model has ~ 97% accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make predictions on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 6, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = nn_model.predict(test_set_x)\n",
    "predictions = np.argmax(predictions, axis = 1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 8us/step\n",
      "\n",
      "acc: 96.21%\n"
     ]
    }
   ],
   "source": [
    "scores_test = nn_model.evaluate(test_set_x, test_set_y)\n",
    "print(\"\\n%s: %.2f%%\" % (nn_model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model has ~96% accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try and look at the different test cases and check which all have gone wrong. Feel free to change the index numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4a07c61eb8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index  = 9997\n",
    "k = test_set_x[index, :]\n",
    "k = k.reshape((28, 28))\n",
    "plt.title('Label is {label}'.format(label=(predictions[index], np.argmax(test_set_y, axis = 1)[index])))\n",
    "plt.imshow(k, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data()\n",
    "\n",
    "X_train = np.concatenate((df[0][0], df[1][0], df[2][0]), axis=0)\n",
    "y_train = np.concatenate((df[0][1], df[1][1], df[2][1]), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
